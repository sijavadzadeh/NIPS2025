{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "690b705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "import importlib\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local libraries\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f393bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload in case of change\n",
    "importlib.reload(utils)\n",
    "from utils import get_data_directory\n",
    "from utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf93163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Config ------------\n",
    "SEGMENT_LENGTH = 125000  # 1 second @ 24kHz was 125 with a single fc layer performed relatively well\n",
    "BATCH_SIZE = 16\n",
    "EMBEDDING_DIM = 128\n",
    "# LEARNING_RATE = 2e-5 # 1e4 had good results\n",
    "LEARNING_RATE = 1e-3 # 1e-4 had good results\n",
    "EPOCHS = 500\n",
    "LOG_DIR = \"runs/siamese_lfp3\"\n",
    "RUN_SIMULATION_DATA = False \n",
    "RUN_REAL_DATA = not RUN_SIMULATION_DATA\n",
    "SIMULATION_DATA_SEPARABLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad389620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Data Preparation ------------\n",
    "def segment_data(data, segment_length):\n",
    "    num_segments = len(data) // segment_length\n",
    "    segments = np.array(np.split(data[:num_segments * segment_length], num_segments))\n",
    "    np.random.shuffle(segments)\n",
    "    return segments\n",
    "\n",
    "\n",
    "# def create_pairs(gpi_segments, stn_segments):\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "\n",
    "#     # GPi-GPi (label 0)\n",
    "#     for i in range(len(gpi_segments) - 1):\n",
    "#         pairs.append((gpi_segments[i], gpi_segments[i+1]))\n",
    "#         labels.append(0)\n",
    "\n",
    "#     # STN-STN (label 0)\n",
    "#     for i in range(len(stn_segments) - 1):\n",
    "#         pairs.append((stn_segments[i], stn_segments[i+1]))\n",
    "#         labels.append(0)\n",
    "\n",
    "#     # GPi-STN (label 1)\n",
    "#     for i in range(min(len(gpi_segments), len(stn_segments))):\n",
    "#         pairs.append((gpi_segments[i], stn_segments[i]))\n",
    "#         labels.append(1)\n",
    "\n",
    "#     ratio_similar = labels.count(0) / len(labels)\n",
    "#     print(f\"Similarity label ratio: {ratio_similar:.2f} similar (label 0), {1 - ratio_similar:.2f} dissimilar (label 1)\")\n",
    "\n",
    "#     return pairs, labels\n",
    "\n",
    "def create_pairs(gpi_segments, stn_segments, max_dataset_size):\n",
    "    # GPi-GPi (label 0)\n",
    "    gpi_gpi_pairs = [(gpi_segments[i], gpi_segments[i+1]) for i in range(len(gpi_segments) - 1)]\n",
    "    gpi_gpi_pairs.extend([(gpi_segments[i], gpi_segments[i+2]) for i in range(len(gpi_segments) - 2)])\n",
    "    gpi_gpi_pairs.extend([(gpi_segments[i], gpi_segments[i+3]) for i in range(len(gpi_segments) - 3)])\n",
    "    gpi_gpi_pairs.extend([(gpi_segments[i], gpi_segments[i+4]) for i in range(len(gpi_segments) - 4)])\n",
    "    gpi_gpi_labels = [0] * len(gpi_gpi_pairs)\n",
    "\n",
    "    # STN-STN (label 0)\n",
    "    stn_stn_pairs = [(stn_segments[i], stn_segments[i+1]) for i in range(len(stn_segments) - 1)]\n",
    "    stn_stn_pairs.extend([(stn_segments[i], stn_segments[i+2]) for i in range(len(stn_segments) - 2)])\n",
    "    stn_stn_pairs.extend([(stn_segments[i], stn_segments[i+3]) for i in range(len(stn_segments) - 3)])\n",
    "    stn_stn_pairs.extend([(stn_segments[i], stn_segments[i+4]) for i in range(len(stn_segments) - 4)])\n",
    "    stn_stn_labels = [0] * len(stn_stn_pairs)\n",
    "\n",
    "    # GPi-STN (label 1)\n",
    "    gpi_stn_pairs = [(gpi_segments[i], stn_segments[i]) for i in range(min(len(gpi_segments), len(stn_segments)))]\n",
    "    gpi_stn_pairs.extend([(gpi_segments[i], stn_segments[i+1]) for i in range(min(len(gpi_segments), len(stn_segments))-1)])\n",
    "    gpi_stn_pairs.extend([(gpi_segments[i+1], stn_segments[i]) for i in range(min(len(gpi_segments), len(stn_segments))-1)])\n",
    "    gpi_stn_pairs.extend([(gpi_segments[i], stn_segments[i+2]) for i in range(min(len(gpi_segments), len(stn_segments))-2)])\n",
    "    gpi_stn_labels = [1] * len(gpi_stn_pairs)\n",
    "\n",
    "    # Combine similar pairs\n",
    "    similar_pairs = gpi_gpi_pairs + stn_stn_pairs\n",
    "    similar_labels = gpi_gpi_labels + stn_stn_labels\n",
    "    similar_labels = [0] * len(similar_pairs)\n",
    "\n",
    "    combined_similar = list(zip(similar_pairs, similar_labels))\n",
    "    np.random.shuffle(combined_similar)\n",
    "    similar_pairs, similar_labels = zip(*combined_similar)\n",
    "    similar_pairs, similar_labels = list(similar_pairs), list(similar_labels)\n",
    "\n",
    "    # Balance both classes\n",
    "    min_len = min(len(similar_pairs), len(gpi_stn_pairs), max_dataset_size)\n",
    "    balanced_pairs = similar_pairs[:min_len] + gpi_stn_pairs[:min_len]\n",
    "    balanced_labels = similar_labels[:min_len] + gpi_stn_labels[:min_len]\n",
    "\n",
    "    ratio_similar = balanced_labels.count(0) / len(balanced_labels)\n",
    "    print(f\"Balanced similarity label ratio: {ratio_similar:.2f} similar (label 0), {1 - ratio_similar:.2f} dissimilar (label 1)\")\n",
    "\n",
    "    return balanced_pairs, balanced_labels\n",
    "\n",
    "\n",
    "class LFPDataset(Dataset):\n",
    "    def __init__(self, pairs, labels):\n",
    "        self.pairs = pairs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, x2 = self.pairs[idx]\n",
    "        x1 = torch.tensor(x1, dtype=torch.float32).unsqueeze(0)\n",
    "        x2 = torch.tensor(x2, dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return x1, x2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86b0c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Model Definition ------------\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        # self.layers = nn.ModuleList([\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv1d(1, 4, kernel_size=16, stride=2, padding=8),\n",
    "        #     nn.BatchNorm1d(4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv1d(4, 8, kernel_size=32, stride=2, padding=16),\n",
    "        #     nn.BatchNorm1d(8),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv1d(8, 16, kernel_size=64, stride=2, padding=32),\n",
    "        #     nn.BatchNorm1d(16),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.1),\n",
    "        #     nn.Conv1d(16, 32, kernel_size=128, stride=2, padding=64),\n",
    "        #     nn.BatchNorm1d(32),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.1),\n",
    "        #     nn.Conv1d(32, 64, kernel_size=256, stride=2, padding=128),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.1),\n",
    "        #     nn.Conv1d(64, 64, kernel_size=512, stride=2, padding=256),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.AdaptiveAvgPool1d(1)\n",
    "        # ])\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(1, 32, kernel_size=32, stride=8, padding=0),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(32, 64, kernel_size=32, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=16, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=8, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        ])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, embedding_dim),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(embedding_dim, embedding_dim//2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(embedding_dim//2,embedding_dim//4)  # Final layer maps to embedding space\n",
    "        )\n",
    "        # self.fc = nn.Linear(64, embedding_dim) # achived 58.8 percent testing accuracy\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def embed(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total:,}\\n\")\n",
    "    print(\"Trainable parameters by layer:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"{name:50} {param.numel():,}\")\n",
    "\n",
    "\n",
    "def print_model_summary(model, train_loader, device):\n",
    "    print(\"===== Sample Forward Pass Shape Info =====\")\n",
    "    x_sample = next(iter(train_loader))[0].to(device)\n",
    "    model.encoder(x_sample)\n",
    "    print(\"\\nModel Summary:\\n\")\n",
    "    print(model)\n",
    "    count_parameters(model)\n",
    "\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.encoder = CNNEncoder(embedding_dim)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        embed1 = self.encoder(x1)\n",
    "        embed2 = self.encoder(x2)\n",
    "        distance = F.pairwise_distance(embed1, embed2)\n",
    "        # distance = 1 - F.cosine_similarity(embed1, embed2)\n",
    "        return distance \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0ee84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- Training Loop ------------\n",
    "def train(model, dataloader, optimizer, criterion, device, writer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x1, x2, label) in enumerate(dataloader):\n",
    "        x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x1, x2)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        preds = (output > 0.5).float()\n",
    "        correct += (preds == label).sum()\n",
    "        total += label.size(0)\n",
    "        if i == 0:\n",
    "            print(\"Train Preds:\", preds[:10])\n",
    "            print(\"Train Labels:\", label[:10])\n",
    "        writer.add_scalar('Train/Batch_Loss', loss.item(), epoch * len(dataloader) + i)\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1} Train Accuracy: {accuracy:.4f}\")\n",
    "    writer.add_scalar('Train/Epoch_Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', accuracy, epoch)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, writer, epoch):\n",
    "    model.eval() # disable drop outs and does batch normalization in validation mode\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tcounter = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, label in dataloader:\n",
    "            tcounter = tcounter + 1\n",
    "            x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n",
    "            output = model(x1, x2)\n",
    "            loss = criterion(output, label)\n",
    "            total_loss += loss.item()\n",
    "            preds = (output > 0.5).float()  # Same for both train and test\n",
    "            correct += (preds == label).sum().item()\n",
    "            total += label.size(0)\n",
    "            if tcounter == 1:\n",
    "                print(\"Test Preds:\", preds[0:15])\n",
    "                print(\"Test Labels:\", label[0:15])\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1} Test Accuracy: {accuracy:.4f}\")\n",
    "    writer.add_scalar('Test/Epoch_Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Test/Accuracy', accuracy, epoch)\n",
    "    return avg_loss\n",
    "\n",
    "def training_validate_loop(model, train_loader, test_loader, device, run_dir, epochs):\n",
    "     \n",
    "    # TensorBoard setup\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(run_dir)\n",
    "\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "    criterion = contrastive_loss\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "    model_save_path = run_dir + \"\\\\full_siamese_model_best.pt\"\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 20\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device, writer, epoch)\n",
    "        validate_loss = evaluate(model, test_loader, criterion, device, writer, epoch)\n",
    "        scheduler.step(validate_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - LR: {current_lr:.10f} - Train Loss: {train_loss:.4f} - Test Loss: {validate_loss:.4f}\")\n",
    "        writer.add_scalar('LearningRate', current_lr, epoch)\n",
    "\n",
    "        # --- Early Stopping & Checkpoint ---\n",
    "        if validate_loss < best_val_loss:\n",
    "            best_val_loss = validate_loss\n",
    "            torch.save(model, model_save_path)\n",
    "            print(f\" New best model saved at epoch {epoch+1}\")\n",
    "            epochs_no_improve = 0\n",
    "\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\" Early stopping at epoch {epoch+1} (no improvement for {patience} epochs)\")\n",
    "                break\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    return torch.load(model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "def contrastive_loss(distances, labels, margin=1.0):\n",
    "        labels = labels.float()\n",
    "        loss_similar = (1 - labels) * distances.pow(2)\n",
    "        loss_dissimilar = labels * F.relu(margin - distances).pow(2)\n",
    "        return torch.mean(loss_similar + loss_dissimilar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "712672f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization \n",
    "def extract_embeddings(model, data_segments, label, device):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for segment in data_segments:\n",
    "            x = torch.tensor(segment, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, T)\n",
    "            embedding = model.embed(x).cpu().numpy().squeeze()\n",
    "            all_embeddings.append((embedding, label))\n",
    "    return all_embeddings\n",
    "\n",
    "def visualize(embeddings_with_labels):\n",
    "    embeddings = np.array([e for e, _ in embeddings_with_labels])\n",
    "    labels = np.array([l for _, l in embeddings_with_labels])\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for label in np.unique(labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(reduced[idx, 0], reduced[idx, 1], label=f\"{'GPi' if label == 0 else 'STN'}\", alpha=0.7)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Functional Embedding Space\")\n",
    "    plt.xlabel(\"t-SNE Dim 1\")\n",
    "    plt.ylabel(\"t-SNE Dim 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7acaf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def create_timestamped_logdir(base_dir=\"runs\"):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    log_dir = os.path.join(base_dir, f\"siamese_{timestamp}\")\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57497af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Information =====\n",
      "Balanced similarity label ratio: 0.50 similar (label 0), 0.50 dissimilar (label 1)\n",
      "Train set: 4736 pairs\n",
      "Test set: 1184 pairs\n",
      "Batch size: 16\n",
      "Running on Real data\n",
      "===== Training Input Shape Info =====\n",
      "Train input shapes: x1: torch.Size([16, 1, 125000]), x2: torch.Size([16, 1, 125000])\n",
      "===== Testing Input Shape Info =====\n",
      "Test input shapes: x1: torch.Size([16, 1, 125000]), x2: torch.Size([16, 1, 125000])\n",
      "\n",
      "\n",
      " Using cuda\n",
      "===== Sample Forward Pass Shape Info =====\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "SiameseNet(\n",
      "  (encoder): CNNEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Conv1d(1, 32, kernel_size=(32,), stride=(8,))\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "      (5): Conv1d(32, 64, kernel_size=(32,), stride=(2,))\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.5, inplace=False)\n",
      "      (9): Conv1d(64, 64, kernel_size=(16,), stride=(2,))\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU()\n",
      "      (12): Dropout(p=0.5, inplace=False)\n",
      "      (13): Conv1d(64, 64, kernel_size=(8,), stride=(2,))\n",
      "      (14): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Dropout(p=0.5, inplace=False)\n",
      "      (17): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (18): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU()\n",
      "      (20): Dropout(p=0.5, inplace=False)\n",
      "      (21): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): ReLU()\n",
      "      (24): Dropout(p=0.5, inplace=False)\n",
      "      (25): AdaptiveAvgPool1d(output_size=1)\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable parameters: 217,344\n",
      "\n",
      "Trainable parameters by layer:\n",
      "encoder.layers.1.weight                            1,024\n",
      "encoder.layers.1.bias                              32\n",
      "encoder.layers.2.weight                            32\n",
      "encoder.layers.2.bias                              32\n",
      "encoder.layers.5.weight                            65,536\n",
      "encoder.layers.5.bias                              64\n",
      "encoder.layers.6.weight                            64\n",
      "encoder.layers.6.bias                              64\n",
      "encoder.layers.9.weight                            65,536\n",
      "encoder.layers.9.bias                              64\n",
      "encoder.layers.10.weight                           64\n",
      "encoder.layers.10.bias                             64\n",
      "encoder.layers.13.weight                           32,768\n",
      "encoder.layers.13.bias                             64\n",
      "encoder.layers.14.weight                           64\n",
      "encoder.layers.14.bias                             64\n",
      "encoder.layers.17.weight                           16,384\n",
      "encoder.layers.17.bias                             64\n",
      "encoder.layers.18.weight                           64\n",
      "encoder.layers.18.bias                             64\n",
      "encoder.layers.21.weight                           16,384\n",
      "encoder.layers.21.bias                             64\n",
      "encoder.layers.22.weight                           64\n",
      "encoder.layers.22.bias                             64\n",
      "encoder.fc.0.weight                                8,192\n",
      "encoder.fc.0.bias                                  128\n",
      "encoder.fc.1.weight                                8,192\n",
      "encoder.fc.1.bias                                  64\n",
      "encoder.fc.2.weight                                2,048\n",
      "encoder.fc.2.bias                                  32\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# # ----------- Run Pipeline ------------\n",
    "# def main():\n",
    "    \n",
    "# pipeline:\n",
    "# get data (simulation or real)\n",
    "# preprocessing normalize data\n",
    "# process data for training\n",
    "# train data (alot of parameters )\n",
    "# visualzied points whether its on validatoin or training set or test set\n",
    "\n",
    "# Get/generate data\n",
    "if RUN_SIMULATION_DATA:\n",
    "    # Generate synthetic LFP-like signals with sinusoids + noise\n",
    "    if SIMULATION_DATA_SEPARABLE == False:\n",
    "        fs = 24414\n",
    "        duration_sec = 60 * 10\n",
    "        t = np.linspace(0, duration_sec, fs * duration_sec, endpoint=False)\n",
    "        gpi_signal = np.sin(2 * np.pi * 10 * t)*0.001  # 10 Hz sinusoid\n",
    "        stn_signal = np.sin(2 * np.pi * 23 * t)*0.001  # 23 Hz sinusoid\n",
    "        GPiData = gpi_signal + 0.0005 * np.random.randn(len(t))\n",
    "        STNData = stn_signal + 0.0005 * np.random.randn(len(t))\n",
    "\n",
    "    # Simulate random LFP-like signals which are not separable \n",
    "    else :\n",
    "        GPiData = np.random.randn(24000 * 60 * 5)*0.001  # 2 minutes of data\n",
    "        STNData = np.random.randn(24000 * 60 * 5)*0.001\n",
    "    \n",
    "else: \n",
    "    # load real data\n",
    "    # for Sina's PC: F:\\Python Projects\\data\\period9\n",
    "    # for shared PC: D:\\Sina\\Data\\period9\\microSTN_L_3_CommonFiltered.mat\n",
    "    dataPath = get_data_directory()\n",
    "    with h5py.File(dataPath+ \"microGPi1_L_4_CommonFiltered.mat\", \"r\") as f:\n",
    "        raw_gpi = np.array(f[\"data\"]).squeeze()\n",
    "        fs = int(np.array(f[\"fs\"]).squeeze())\n",
    "    with h5py.File(dataPath + \"microSTN_L_3_CommonFiltered.mat\", \"r\") as f:\n",
    "        raw_stn = np.array(f[\"data\"]).squeeze()  # replace with your actual filename\n",
    "\n",
    "    # normalization \n",
    "    GPiData = (raw_gpi - np.mean(raw_gpi)) / np.std(raw_gpi)\n",
    "    STNData = (raw_stn - np.mean(raw_stn)) / np.std(raw_stn)\n",
    "\n",
    "\n",
    "# Print dataset shape and sizes\n",
    "print(\"===== Dataset Information =====\")\n",
    "\n",
    "# Segment\n",
    "gpi_segments = segment_data(GPiData, SEGMENT_LENGTH)\n",
    "stn_segments = segment_data(STNData, SEGMENT_LENGTH)\n",
    "max_dataset_size = 5000\n",
    "pairs, labels = create_pairs(gpi_segments, stn_segments, max_dataset_size)\n",
    "\n",
    "# Split data\n",
    "train_pairs, test_pairs, train_labels, test_labels = train_test_split( pairs, labels, test_size=0.2, stratify=labels, shuffle=True, random_state=42)\n",
    "\n",
    "# Dataloaders\n",
    "train_ds = LFPDataset(train_pairs, train_labels)\n",
    "test_ds = LFPDataset(test_pairs, test_labels)\n",
    "print(f\"Train set: {len(train_ds)} pairs\")\n",
    "print(f\"Test set: {len(test_ds)} pairs\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "print(f\"Running on \" + \"Real data\" if RUN_REAL_DATA else \"Simulated data\")\n",
    "print(\"===== Training Input Shape Info =====\")\n",
    "for x1, x2, _ in train_loader:\n",
    "    print(f\"Train input shapes: x1: {x1.shape}, x2: {x2.shape}\")\n",
    "    break\n",
    "print(\"===== Testing Input Shape Info =====\")\n",
    "for x1, x2, _ in test_loader:\n",
    "    print(f\"Test input shapes: x1: {x1.shape}, x2: {x2.shape}\\n\\n\")\n",
    "    break\n",
    "\n",
    "\n",
    "# Check GPU\n",
    "device = get_device()\n",
    "print(f\" Using {device}\")\n",
    "\n",
    "# Model setup\n",
    "model = SiameseNet(embedding_dim=EMBEDDING_DIM).to(device)\n",
    "print_model_summary(model, train_loader, device)\n",
    "\n",
    "run_name = create_timestamped_logdir() + \"\" #add name if you want\n",
    "trained_model = training_validate_loop(model, train_loader, test_loader, device, run_name, EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f65c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb607ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_embeddings.py\n",
    "\n",
    "\n",
    "# model = SiameseNet(embedding_dim=EMBEDDING_DIM).to(device)\n",
    "# model.load_state_dict(torch.load(\"only weights_siamese_model.pt\", map_location=device))\n",
    "trained_model= torch.load(\"runs/siamese_2025-04-22_18-20/full_siamese_model_best.pt\", weights_only=False)\n",
    "trained_model.eval()\n",
    "encoder_model = trained_model.encoder\n",
    "encoder_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "dataPath = get_data_directory()\n",
    "with h5py.File(dataPath+ \"microGPi1_L_5_CommonFiltered.mat\", \"r\") as f:\n",
    "    raw_gpi = np.array(f[\"data\"]).squeeze()\n",
    "    fs = int(np.array(f[\"fs\"]).squeeze())\n",
    "with h5py.File(dataPath + \"microSTN_L_2_CommonFiltered.mat\", \"r\") as f:\n",
    "    raw_stn = np.array(f[\"data\"]).squeeze()  # replace with your actual filename\n",
    "\n",
    "# normalization \n",
    "gpi_data = (raw_gpi - np.mean(raw_gpi)) / np.std(raw_gpi)\n",
    "stn_data = (raw_stn - np.mean(raw_stn)) / np.std(raw_stn)\n",
    "\n",
    "gpi_segments = segment_data(gpi_data, SEGMENT_LENGTH)[:500]  # take first 100 segments\n",
    "stn_segments = segment_data(stn_data, SEGMENT_LENGTH)[:500]\n",
    "\n",
    "gpi_embeddings = extract_embeddings(encoder_model, gpi_segments, label=0, device=device)\n",
    "stn_embeddings = extract_embeddings(encoder_model, stn_segments, label=1, device=device)\n",
    "\n",
    "all_embeddings = gpi_embeddings + stn_embeddings\n",
    "visualize(all_embeddings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689ed3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63026eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932b4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72693393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436271d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Information =====\n",
      "Balanced similarity label ratio: 0.50 similar (label 0), 0.50 dissimilar (label 1)\n",
      "Train set: 4736 pairs\n",
      "Test set: 1184 pairs\n",
      "Batch size: 16\n",
      "Running on Real data\n",
      "\n",
      "\n",
      "===== Training Input Shape Info =====\n",
      "Train input shapes: x1: torch.Size([16, 1, 125000]), x2: torch.Size([16, 1, 125000])\n",
      "===== Testing Input Shape Info =====\n",
      "Test input shapes: x1: torch.Size([16, 1, 125000]), x2: torch.Size([16, 1, 125000])\n",
      " Using cpu\n",
      "===== Sample Forward Pass Shape Info =====\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "SiameseNet(\n",
      "  (encoder): CNNEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Conv1d(1, 32, kernel_size=(32,), stride=(8,))\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "      (5): Conv1d(32, 64, kernel_size=(32,), stride=(2,))\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.5, inplace=False)\n",
      "      (9): Conv1d(64, 64, kernel_size=(16,), stride=(2,))\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU()\n",
      "      (12): Dropout(p=0.5, inplace=False)\n",
      "      (13): Conv1d(64, 64, kernel_size=(8,), stride=(2,))\n",
      "      (14): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Dropout(p=0.5, inplace=False)\n",
      "      (17): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (18): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU()\n",
      "      (20): Dropout(p=0.5, inplace=False)\n",
      "      (21): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): ReLU()\n",
      "      (24): Dropout(p=0.5, inplace=False)\n",
      "      (25): AdaptiveAvgPool1d(output_size=1)\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable parameters: 217,344\n",
      "\n",
      "Trainable parameters by layer:\n",
      "encoder.layers.1.weight                            1,024\n",
      "encoder.layers.1.bias                              32\n",
      "encoder.layers.2.weight                            32\n",
      "encoder.layers.2.bias                              32\n",
      "encoder.layers.5.weight                            65,536\n",
      "encoder.layers.5.bias                              64\n",
      "encoder.layers.6.weight                            64\n",
      "encoder.layers.6.bias                              64\n",
      "encoder.layers.9.weight                            65,536\n",
      "encoder.layers.9.bias                              64\n",
      "encoder.layers.10.weight                           64\n",
      "encoder.layers.10.bias                             64\n",
      "encoder.layers.13.weight                           32,768\n",
      "encoder.layers.13.bias                             64\n",
      "encoder.layers.14.weight                           64\n",
      "encoder.layers.14.bias                             64\n",
      "encoder.layers.17.weight                           16,384\n",
      "encoder.layers.17.bias                             64\n",
      "encoder.layers.18.weight                           64\n",
      "encoder.layers.18.bias                             64\n",
      "encoder.layers.21.weight                           16,384\n",
      "encoder.layers.21.bias                             64\n",
      "encoder.layers.22.weight                           64\n",
      "encoder.layers.22.bias                             64\n",
      "encoder.fc.0.weight                                8,192\n",
      "encoder.fc.0.bias                                  128\n",
      "encoder.fc.1.weight                                8,192\n",
      "encoder.fc.1.bias                                  64\n",
      "encoder.fc.2.weight                                2,048\n",
      "encoder.fc.2.bias                                  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python Projects\\NIPS2025\\utils.py:20: RuntimeWarning:  CUDA is not available. The model will run on CPU, which may be slower.\n",
      "  warnings.warn(\" CUDA is not available. The model will run on CPU, which may be slower.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 1 Train Accuracy: 0.5239\n",
      "Test Preds: tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 1 Test Accuracy: 0.8066\n",
      "Epoch 1 - LR: 0.001000 - Train Loss: 0.2946 - Test Loss: 0.3603\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 2 Train Accuracy: 0.5416\n",
      "Test Preds: tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 2 Test Accuracy: 0.6242\n",
      "Epoch 2 - LR: 0.001000 - Train Loss: 0.2872 - Test Loss: 0.4634\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 3 Train Accuracy: 0.5598\n",
      "Test Preds: tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 3 Test Accuracy: 0.7627\n",
      "Epoch 3 - LR: 0.001000 - Train Loss: 0.2802 - Test Loss: 0.3323\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 4 Train Accuracy: 0.5709\n",
      "Test Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 4 Test Accuracy: 0.5566\n",
      "Epoch 4 - LR: 0.001000 - Train Loss: 0.2650 - Test Loss: 0.2842\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 5 Train Accuracy: 0.6518\n",
      "Test Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 5 Test Accuracy: 0.5127\n",
      "Epoch 5 - LR: 0.001000 - Train Loss: 0.2327 - Test Loss: 0.3498\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 6 Train Accuracy: 0.6047\n",
      "Test Preds: tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 6 Test Accuracy: 0.6115\n",
      "Epoch 6 - LR: 0.001000 - Train Loss: 0.2477 - Test Loss: 2.4830\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 7 Train Accuracy: 0.7557\n",
      "Test Preds: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 7 Test Accuracy: 0.5870\n",
      "Epoch 7 - LR: 0.001000 - Train Loss: 0.1705 - Test Loss: 3.1482\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 8 Train Accuracy: 0.8167\n",
      "Test Preds: tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 8 Test Accuracy: 0.5650\n",
      "Epoch 8 - LR: 0.001000 - Train Loss: 0.1446 - Test Loss: 3.5802\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 9 Train Accuracy: 0.8659\n",
      "Test Preds: tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 9 Test Accuracy: 0.5735\n",
      "Epoch 9 - LR: 0.001000 - Train Loss: 0.1076 - Test Loss: 3.1035\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 10 Train Accuracy: 0.8809\n",
      "Test Preds: tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 10 Test Accuracy: 0.5802\n",
      "Epoch 10 - LR: 0.000500 - Train Loss: 0.0996 - Test Loss: 5.6882\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     model = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     78\u001b[39m print_model_summary(model, train_loader, device)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     test_loss = evaluate(model, test_loader, criterion, device, writer, epoch)\n\u001b[32m     84\u001b[39m     scheduler.step(test_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optimizer, criterion, device, writer, epoch)\u001b[39m\n\u001b[32m      8\u001b[39m x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m loss = criterion(output, label)\n\u001b[32m     12\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mSiameseNet.forward\u001b[39m\u001b[34m(self, x1, x2)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     embed1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     embed2 = \u001b[38;5;28mself\u001b[39m.encoder(x2)\n\u001b[32m    107\u001b[39m     distance = F.pairwise_distance(embed1, embed2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mCNNEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     77\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fc(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Python Projects\\NIPS2025\\venv311\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # Run\n",
    "# if __name__ == \"__main__\":\n",
    "#     model = main()x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Information =====\n",
      "Balanced similarity label ratio: 0.50 similar (label 0), 0.50 dissimilar (label 1)\n",
      "Train set: 1185 pairs\n",
      "Test set: 297 pairs\n",
      "Batch size: 16\n",
      "cpu\n",
      "===== Sample Forward Pass Shape Info =====\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "SiameseNet(\n",
      "  (encoder): CNNEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Conv1d(1, 32, kernel_size=(32,), stride=(8,))\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "      (5): Conv1d(32, 64, kernel_size=(32,), stride=(2,))\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.5, inplace=False)\n",
      "      (9): Conv1d(64, 64, kernel_size=(16,), stride=(2,))\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU()\n",
      "      (12): Dropout(p=0.5, inplace=False)\n",
      "      (13): Conv1d(64, 64, kernel_size=(8,), stride=(2,))\n",
      "      (14): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Dropout(p=0.5, inplace=False)\n",
      "      (17): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (18): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU()\n",
      "      (20): Dropout(p=0.5, inplace=False)\n",
      "      (21): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): ReLU()\n",
      "      (24): Dropout(p=0.5, inplace=False)\n",
      "      (25): AdaptiveAvgPool1d(output_size=1)\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable parameters: 217,344\n",
      "\n",
      "Trainable parameters by layer:\n",
      "encoder.layers.1.weight                            1,024\n",
      "encoder.layers.1.bias                              32\n",
      "encoder.layers.2.weight                            32\n",
      "encoder.layers.2.bias                              32\n",
      "encoder.layers.5.weight                            65,536\n",
      "encoder.layers.5.bias                              64\n",
      "encoder.layers.6.weight                            64\n",
      "encoder.layers.6.bias                              64\n",
      "encoder.layers.9.weight                            65,536\n",
      "encoder.layers.9.bias                              64\n",
      "encoder.layers.10.weight                           64\n",
      "encoder.layers.10.bias                             64\n",
      "encoder.layers.13.weight                           32,768\n",
      "encoder.layers.13.bias                             64\n",
      "encoder.layers.14.weight                           64\n",
      "encoder.layers.14.bias                             64\n",
      "encoder.layers.17.weight                           16,384\n",
      "encoder.layers.17.bias                             64\n",
      "encoder.layers.18.weight                           64\n",
      "encoder.layers.18.bias                             64\n",
      "encoder.layers.21.weight                           16,384\n",
      "encoder.layers.21.bias                             64\n",
      "encoder.layers.22.weight                           64\n",
      "encoder.layers.22.bias                             64\n",
      "encoder.fc.0.weight                                8,192\n",
      "encoder.fc.0.bias                                  128\n",
      "encoder.fc.1.weight                                8,192\n",
      "encoder.fc.1.bias                                  64\n",
      "encoder.fc.2.weight                                2,048\n",
      "encoder.fc.2.bias                                  32\n",
      "===== Training Input Shape Info =====\n",
      "Train input shapes: x1: torch.Size([16, 1, 125000]), x2: torch.Size([16, 1, 125000])\n",
      "===== Testing Input Shape Info =====\n",
      "Test input shapes: x1: torch.Size([16, 1, 125000]), x2: torch.Size([16, 1, 125000])\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Epoch 1 Train Accuracy: 0.5063\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 1 Test Accuracy: 0.5017\n",
      "Epoch 1/500, Train Loss: 0.3731, Test Loss: 0.4812\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 2 Train Accuracy: 0.5038\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 2 Test Accuracy: 0.5017\n",
      "Epoch 2/500, Train Loss: 0.3627, Test Loss: 0.4804\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 3 Train Accuracy: 0.5215\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 3 Test Accuracy: 0.5017\n",
      "Epoch 3/500, Train Loss: 0.3653, Test Loss: 0.4806\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 4 Train Accuracy: 0.5021\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 4 Test Accuracy: 0.5017\n",
      "Epoch 4/500, Train Loss: 0.3544, Test Loss: 0.4793\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 5 Train Accuracy: 0.5004\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 5 Test Accuracy: 0.5017\n",
      "Epoch 5/500, Train Loss: 0.3709, Test Loss: 0.4788\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 6 Train Accuracy: 0.5131\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 6 Test Accuracy: 0.5017\n",
      "Epoch 6/500, Train Loss: 0.3533, Test Loss: 0.4759\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 7 Train Accuracy: 0.5131\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 7 Test Accuracy: 0.5017\n",
      "Epoch 7/500, Train Loss: 0.3394, Test Loss: 0.4683\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 8 Train Accuracy: 0.5114\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 8 Test Accuracy: 0.5017\n",
      "Epoch 8/500, Train Loss: 0.3224, Test Loss: 0.4644\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 9 Train Accuracy: 0.4987\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 9 Test Accuracy: 0.5017\n",
      "Epoch 9/500, Train Loss: 0.3302, Test Loss: 0.4534\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 10 Train Accuracy: 0.5021\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 10 Test Accuracy: 0.5017\n",
      "Epoch 10/500, Train Loss: 0.3228, Test Loss: 0.4517\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 11 Train Accuracy: 0.5013\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 11 Test Accuracy: 0.5017\n",
      "Epoch 11/500, Train Loss: 0.3134, Test Loss: 0.4472\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 12 Train Accuracy: 0.5165\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 12 Test Accuracy: 0.5017\n",
      "Epoch 12/500, Train Loss: 0.2897, Test Loss: 0.4499\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 13 Train Accuracy: 0.5165\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 13 Test Accuracy: 0.5017\n",
      "Epoch 13/500, Train Loss: 0.2987, Test Loss: 0.4485\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 14 Train Accuracy: 0.5173\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 14 Test Accuracy: 0.5017\n",
      "Epoch 14/500, Train Loss: 0.3136, Test Loss: 0.4410\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 15 Train Accuracy: 0.5063\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 15 Test Accuracy: 0.5017\n",
      "Epoch 15/500, Train Loss: 0.3061, Test Loss: 0.4668\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 16 Train Accuracy: 0.5131\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 16 Test Accuracy: 0.5017\n",
      "Epoch 16/500, Train Loss: 0.3200, Test Loss: 0.4362\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 17 Train Accuracy: 0.5097\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 17 Test Accuracy: 0.5017\n",
      "Epoch 17/500, Train Loss: 0.3056, Test Loss: 0.4529\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Epoch 18 Train Accuracy: 0.5063\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 18 Test Accuracy: 0.4916\n",
      "Epoch 18/500, Train Loss: 0.2985, Test Loss: 0.4349\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 19 Train Accuracy: 0.5080\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 19 Test Accuracy: 0.4983\n",
      "Epoch 19/500, Train Loss: 0.2998, Test Loss: 0.4102\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 20 Train Accuracy: 0.5122\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 20 Test Accuracy: 0.4882\n",
      "Epoch 20/500, Train Loss: 0.3080, Test Loss: 0.4306\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 21 Train Accuracy: 0.5207\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 21 Test Accuracy: 0.4882\n",
      "Epoch 21/500, Train Loss: 0.3014, Test Loss: 0.4193\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 22 Train Accuracy: 0.5080\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 22 Test Accuracy: 0.4949\n",
      "Epoch 22/500, Train Loss: 0.3103, Test Loss: 0.4128\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 23 Train Accuracy: 0.5266\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 23 Test Accuracy: 0.4983\n",
      "Epoch 23/500, Train Loss: 0.2931, Test Loss: 0.4169\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 24 Train Accuracy: 0.5038\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 24 Test Accuracy: 0.4983\n",
      "Epoch 24/500, Train Loss: 0.3044, Test Loss: 0.4051\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 25 Train Accuracy: 0.5148\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 25 Test Accuracy: 0.4983\n",
      "Epoch 25/500, Train Loss: 0.3007, Test Loss: 0.4048\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 26 Train Accuracy: 0.4996\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 26 Test Accuracy: 0.5185\n",
      "Epoch 26/500, Train Loss: 0.3096, Test Loss: 0.4052\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 27 Train Accuracy: 0.5502\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 27 Test Accuracy: 0.5320\n",
      "Epoch 27/500, Train Loss: 0.2850, Test Loss: 0.3944\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 28 Train Accuracy: 0.5139\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 28 Test Accuracy: 0.5387\n",
      "Epoch 28/500, Train Loss: 0.3002, Test Loss: 0.3984\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 29 Train Accuracy: 0.5105\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 29 Test Accuracy: 0.5286\n",
      "Epoch 29/500, Train Loss: 0.3010, Test Loss: 0.4048\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 30 Train Accuracy: 0.5359\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 30 Test Accuracy: 0.5286\n",
      "Epoch 30/500, Train Loss: 0.2879, Test Loss: 0.4045\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 31 Train Accuracy: 0.5384\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 31 Test Accuracy: 0.5253\n",
      "Epoch 31/500, Train Loss: 0.2913, Test Loss: 0.4006\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 32 Train Accuracy: 0.5207\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 32 Test Accuracy: 0.5286\n",
      "Epoch 32/500, Train Loss: 0.3018, Test Loss: 0.4008\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 33 Train Accuracy: 0.5257\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 33 Test Accuracy: 0.5286\n",
      "Epoch 33/500, Train Loss: 0.2839, Test Loss: 0.4082\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 34 Train Accuracy: 0.5443\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 34 Test Accuracy: 0.5253\n",
      "Epoch 34/500, Train Loss: 0.2703, Test Loss: 0.4036\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 35 Train Accuracy: 0.5291\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 35 Test Accuracy: 0.5253\n",
      "Epoch 35/500, Train Loss: 0.2874, Test Loss: 0.4057\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 36 Train Accuracy: 0.5376\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 36 Test Accuracy: 0.4949\n",
      "Epoch 36/500, Train Loss: 0.2852, Test Loss: 0.4124\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 37 Train Accuracy: 0.5603\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 37 Test Accuracy: 0.4916\n",
      "Epoch 37/500, Train Loss: 0.2725, Test Loss: 0.4239\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 38 Train Accuracy: 0.5519\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 38 Test Accuracy: 0.5017\n",
      "Epoch 38/500, Train Loss: 0.2707, Test Loss: 0.4195\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 39 Train Accuracy: 0.5646\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 39 Test Accuracy: 0.5017\n",
      "Epoch 39/500, Train Loss: 0.2587, Test Loss: 0.4254\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 40 Train Accuracy: 0.5308\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 40 Test Accuracy: 0.5017\n",
      "Epoch 40/500, Train Loss: 0.2696, Test Loss: 0.4353\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 41 Train Accuracy: 0.5789\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 41 Test Accuracy: 0.5017\n",
      "Epoch 41/500, Train Loss: 0.2547, Test Loss: 0.4345\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 42 Train Accuracy: 0.6093\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 42 Test Accuracy: 0.5017\n",
      "Epoch 42/500, Train Loss: 0.2538, Test Loss: 0.4026\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 43 Train Accuracy: 0.5924\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 43 Test Accuracy: 0.5017\n",
      "Epoch 43/500, Train Loss: 0.2619, Test Loss: 0.4322\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 44 Train Accuracy: 0.5747\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 44 Test Accuracy: 0.5017\n",
      "Epoch 44/500, Train Loss: 0.2742, Test Loss: 0.4011\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 45 Train Accuracy: 0.5857\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 45 Test Accuracy: 0.5017\n",
      "Epoch 45/500, Train Loss: 0.2698, Test Loss: 0.4394\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 46 Train Accuracy: 0.5781\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 46 Test Accuracy: 0.5017\n",
      "Epoch 46/500, Train Loss: 0.2594, Test Loss: 0.4254\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 47 Train Accuracy: 0.5941\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 47 Test Accuracy: 0.5017\n",
      "Epoch 47/500, Train Loss: 0.2463, Test Loss: 0.3965\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 48 Train Accuracy: 0.6051\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 48 Test Accuracy: 0.5118\n",
      "Epoch 48/500, Train Loss: 0.2545, Test Loss: 0.3858\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 49 Train Accuracy: 0.5722\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 49 Test Accuracy: 0.5017\n",
      "Epoch 49/500, Train Loss: 0.2514, Test Loss: 0.4213\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 50 Train Accuracy: 0.5966\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 50 Test Accuracy: 0.5017\n",
      "Epoch 50/500, Train Loss: 0.2514, Test Loss: 0.4102\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 51 Train Accuracy: 0.5772\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 51 Test Accuracy: 0.5017\n",
      "Epoch 51/500, Train Loss: 0.2687, Test Loss: 0.4288\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 52 Train Accuracy: 0.5814\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 52 Test Accuracy: 0.5017\n",
      "Epoch 52/500, Train Loss: 0.2633, Test Loss: 0.4245\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 53 Train Accuracy: 0.6017\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 53 Test Accuracy: 0.5084\n",
      "Epoch 53/500, Train Loss: 0.2528, Test Loss: 0.3926\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 54 Train Accuracy: 0.5814\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 54 Test Accuracy: 0.5017\n",
      "Epoch 54/500, Train Loss: 0.2565, Test Loss: 0.4154\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 55 Train Accuracy: 0.6093\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 55 Test Accuracy: 0.5017\n",
      "Epoch 55/500, Train Loss: 0.2474, Test Loss: 0.4070\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 56 Train Accuracy: 0.5831\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 56 Test Accuracy: 0.5118\n",
      "Epoch 56/500, Train Loss: 0.2492, Test Loss: 0.3768\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 57 Train Accuracy: 0.5755\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 57 Test Accuracy: 0.5017\n",
      "Epoch 57/500, Train Loss: 0.2517, Test Loss: 0.3656\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 58 Train Accuracy: 0.5823\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 58 Test Accuracy: 0.4949\n",
      "Epoch 58/500, Train Loss: 0.2555, Test Loss: 0.3630\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 59 Train Accuracy: 0.5966\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 59 Test Accuracy: 0.5017\n",
      "Epoch 59/500, Train Loss: 0.2477, Test Loss: 0.3646\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 60 Train Accuracy: 0.5890\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 60 Test Accuracy: 0.5152\n",
      "Epoch 60/500, Train Loss: 0.2415, Test Loss: 0.3902\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 61 Train Accuracy: 0.6160\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 61 Test Accuracy: 0.5084\n",
      "Epoch 61/500, Train Loss: 0.2413, Test Loss: 0.3428\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 62 Train Accuracy: 0.5840\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 62 Test Accuracy: 0.4983\n",
      "Epoch 62/500, Train Loss: 0.2585, Test Loss: 0.3710\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 63 Train Accuracy: 0.6034\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 63 Test Accuracy: 0.5084\n",
      "Epoch 63/500, Train Loss: 0.2498, Test Loss: 0.3698\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 64 Train Accuracy: 0.6278\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 64 Test Accuracy: 0.5051\n",
      "Epoch 64/500, Train Loss: 0.2366, Test Loss: 0.3792\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 65 Train Accuracy: 0.6076\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 65 Test Accuracy: 0.5084\n",
      "Epoch 65/500, Train Loss: 0.2382, Test Loss: 0.3845\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 66 Train Accuracy: 0.6211\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 66 Test Accuracy: 0.5017\n",
      "Epoch 66/500, Train Loss: 0.2444, Test Loss: 0.4033\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "Epoch 67 Train Accuracy: 0.6051\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 67 Test Accuracy: 0.5051\n",
      "Epoch 67/500, Train Loss: 0.2440, Test Loss: 0.3583\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 68 Train Accuracy: 0.6143\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 68 Test Accuracy: 0.5017\n",
      "Epoch 68/500, Train Loss: 0.2381, Test Loss: 0.4218\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 69 Train Accuracy: 0.5705\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 69 Test Accuracy: 0.4983\n",
      "Epoch 69/500, Train Loss: 0.2477, Test Loss: 0.3762\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 70 Train Accuracy: 0.6321\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 70 Test Accuracy: 0.5017\n",
      "Epoch 70/500, Train Loss: 0.2287, Test Loss: 0.3686\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 71 Train Accuracy: 0.6000\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 71 Test Accuracy: 0.5017\n",
      "Epoch 71/500, Train Loss: 0.2417, Test Loss: 0.3654\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 72 Train Accuracy: 0.5924\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 72 Test Accuracy: 0.4983\n",
      "Epoch 72/500, Train Loss: 0.2505, Test Loss: 0.3525\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "Epoch 73 Train Accuracy: 0.6059\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 73 Test Accuracy: 0.5017\n",
      "Epoch 73/500, Train Loss: 0.2519, Test Loss: 0.3542\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 74 Train Accuracy: 0.6084\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 74 Test Accuracy: 0.5017\n",
      "Epoch 74/500, Train Loss: 0.2420, Test Loss: 0.3569\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 75 Train Accuracy: 0.6186\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 75 Test Accuracy: 0.5084\n",
      "Epoch 75/500, Train Loss: 0.2424, Test Loss: 0.3864\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 76 Train Accuracy: 0.5848\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 76 Test Accuracy: 0.4983\n",
      "Epoch 76/500, Train Loss: 0.2570, Test Loss: 0.3658\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 77 Train Accuracy: 0.6127\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 77 Test Accuracy: 0.5118\n",
      "Epoch 77/500, Train Loss: 0.2481, Test Loss: 0.3972\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 78 Train Accuracy: 0.5975\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 78 Test Accuracy: 0.4983\n",
      "Epoch 78/500, Train Loss: 0.2421, Test Loss: 0.3520\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 79 Train Accuracy: 0.6177\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 79 Test Accuracy: 0.4983\n",
      "Epoch 79/500, Train Loss: 0.2455, Test Loss: 0.3491\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 80 Train Accuracy: 0.6059\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 80 Test Accuracy: 0.5017\n",
      "Epoch 80/500, Train Loss: 0.2406, Test Loss: 0.3593\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 81 Train Accuracy: 0.6110\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 81 Test Accuracy: 0.5185\n",
      "Epoch 81/500, Train Loss: 0.2472, Test Loss: 0.3391\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 82 Train Accuracy: 0.6219\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 82 Test Accuracy: 0.5017\n",
      "Epoch 82/500, Train Loss: 0.2459, Test Loss: 0.3550\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 83 Train Accuracy: 0.6051\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 83 Test Accuracy: 0.5017\n",
      "Epoch 83/500, Train Loss: 0.2324, Test Loss: 0.3578\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 84 Train Accuracy: 0.6287\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 84 Test Accuracy: 0.5017\n",
      "Epoch 84/500, Train Loss: 0.2278, Test Loss: 0.3588\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 85 Train Accuracy: 0.6236\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 85 Test Accuracy: 0.4983\n",
      "Epoch 85/500, Train Loss: 0.2214, Test Loss: 0.3562\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 86 Train Accuracy: 0.5899\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 86 Test Accuracy: 0.5017\n",
      "Epoch 86/500, Train Loss: 0.2419, Test Loss: 0.4056\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 87 Train Accuracy: 0.6329\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 87 Test Accuracy: 0.5017\n",
      "Epoch 87/500, Train Loss: 0.2398, Test Loss: 0.3609\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 88 Train Accuracy: 0.6236\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 88 Test Accuracy: 0.4983\n",
      "Epoch 88/500, Train Loss: 0.2298, Test Loss: 0.3665\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 89 Train Accuracy: 0.5823\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 89 Test Accuracy: 0.5017\n",
      "Epoch 89/500, Train Loss: 0.2451, Test Loss: 0.3542\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 90 Train Accuracy: 0.6076\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 90 Test Accuracy: 0.4983\n",
      "Epoch 90/500, Train Loss: 0.2423, Test Loss: 0.3579\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 91 Train Accuracy: 0.6287\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 91 Test Accuracy: 0.5084\n",
      "Epoch 91/500, Train Loss: 0.2392, Test Loss: 0.3544\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 92 Train Accuracy: 0.6059\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 92 Test Accuracy: 0.5051\n",
      "Epoch 92/500, Train Loss: 0.2388, Test Loss: 0.3421\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 93 Train Accuracy: 0.6439\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 93 Test Accuracy: 0.4983\n",
      "Epoch 93/500, Train Loss: 0.2288, Test Loss: 0.3649\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 94 Train Accuracy: 0.6186\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 94 Test Accuracy: 0.5219\n",
      "Epoch 94/500, Train Loss: 0.2352, Test Loss: 0.3597\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Epoch 95 Train Accuracy: 0.6481\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 95 Test Accuracy: 0.4983\n",
      "Epoch 95/500, Train Loss: 0.2291, Test Loss: 0.3561\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Epoch 96 Train Accuracy: 0.6380\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 96 Test Accuracy: 0.5017\n",
      "Epoch 96/500, Train Loss: 0.2289, Test Loss: 0.3625\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 97 Train Accuracy: 0.6270\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 97 Test Accuracy: 0.5051\n",
      "Epoch 97/500, Train Loss: 0.2295, Test Loss: 0.3501\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 98 Train Accuracy: 0.6430\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 98 Test Accuracy: 0.5017\n",
      "Epoch 98/500, Train Loss: 0.2225, Test Loss: 0.3628\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 99 Train Accuracy: 0.6549\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 99 Test Accuracy: 0.5320\n",
      "Epoch 99/500, Train Loss: 0.2288, Test Loss: 0.3537\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 100 Train Accuracy: 0.6253\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 100 Test Accuracy: 0.5286\n",
      "Epoch 100/500, Train Loss: 0.2282, Test Loss: 0.3503\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 101 Train Accuracy: 0.6253\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 101 Test Accuracy: 0.4949\n",
      "Epoch 101/500, Train Loss: 0.2373, Test Loss: 0.3814\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Epoch 102 Train Accuracy: 0.6228\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 102 Test Accuracy: 0.5286\n",
      "Epoch 102/500, Train Loss: 0.2357, Test Loss: 0.3561\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 103 Train Accuracy: 0.6211\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 103 Test Accuracy: 0.4949\n",
      "Epoch 103/500, Train Loss: 0.2293, Test Loss: 0.3742\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 104 Train Accuracy: 0.6278\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 104 Test Accuracy: 0.5286\n",
      "Epoch 104/500, Train Loss: 0.2294, Test Loss: 0.3533\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 105 Train Accuracy: 0.6354\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 105 Test Accuracy: 0.4983\n",
      "Epoch 105/500, Train Loss: 0.2305, Test Loss: 0.3720\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 106 Train Accuracy: 0.6489\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 106 Test Accuracy: 0.5017\n",
      "Epoch 106/500, Train Loss: 0.2235, Test Loss: 0.3782\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 107 Train Accuracy: 0.6304\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 107 Test Accuracy: 0.5219\n",
      "Epoch 107/500, Train Loss: 0.2269, Test Loss: 0.3514\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 108 Train Accuracy: 0.6641\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 108 Test Accuracy: 0.5219\n",
      "Epoch 108/500, Train Loss: 0.2186, Test Loss: 0.3600\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 109 Train Accuracy: 0.6616\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 109 Test Accuracy: 0.5253\n",
      "Epoch 109/500, Train Loss: 0.2097, Test Loss: 0.3543\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 110 Train Accuracy: 0.6346\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 110 Test Accuracy: 0.5320\n",
      "Epoch 110/500, Train Loss: 0.2306, Test Loss: 0.3593\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 111 Train Accuracy: 0.6616\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 111 Test Accuracy: 0.5387\n",
      "Epoch 111/500, Train Loss: 0.2158, Test Loss: 0.3643\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 112 Train Accuracy: 0.6726\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 112 Test Accuracy: 0.5421\n",
      "Epoch 112/500, Train Loss: 0.2151, Test Loss: 0.3513\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 113 Train Accuracy: 0.6734\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 113 Test Accuracy: 0.5354\n",
      "Epoch 113/500, Train Loss: 0.2134, Test Loss: 0.3577\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Epoch 114 Train Accuracy: 0.6759\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 114 Test Accuracy: 0.5219\n",
      "Epoch 114/500, Train Loss: 0.2096, Test Loss: 0.3663\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 115 Train Accuracy: 0.6633\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 115 Test Accuracy: 0.5354\n",
      "Epoch 115/500, Train Loss: 0.2265, Test Loss: 0.3685\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 116 Train Accuracy: 0.6574\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 116 Test Accuracy: 0.5286\n",
      "Epoch 116/500, Train Loss: 0.2235, Test Loss: 0.3796\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 117 Train Accuracy: 0.6844\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 117 Test Accuracy: 0.5219\n",
      "Epoch 117/500, Train Loss: 0.2240, Test Loss: 0.3766\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 118 Train Accuracy: 0.6768\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 118 Test Accuracy: 0.5387\n",
      "Epoch 118/500, Train Loss: 0.2064, Test Loss: 0.3752\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 119 Train Accuracy: 0.6692\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 119 Test Accuracy: 0.5354\n",
      "Epoch 119/500, Train Loss: 0.2054, Test Loss: 0.3643\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 120 Train Accuracy: 0.6717\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 120 Test Accuracy: 0.5320\n",
      "Epoch 120/500, Train Loss: 0.2157, Test Loss: 0.3677\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 121 Train Accuracy: 0.6979\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 121 Test Accuracy: 0.5387\n",
      "Epoch 121/500, Train Loss: 0.2093, Test Loss: 0.3602\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "Epoch 122 Train Accuracy: 0.6886\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 122 Test Accuracy: 0.5354\n",
      "Epoch 122/500, Train Loss: 0.2176, Test Loss: 0.3613\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 123 Train Accuracy: 0.6700\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 123 Test Accuracy: 0.5488\n",
      "Epoch 123/500, Train Loss: 0.2033, Test Loss: 0.3780\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 124 Train Accuracy: 0.6641\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 124 Test Accuracy: 0.5320\n",
      "Epoch 124/500, Train Loss: 0.2142, Test Loss: 0.3738\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 125 Train Accuracy: 0.6827\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 125 Test Accuracy: 0.5286\n",
      "Epoch 125/500, Train Loss: 0.2147, Test Loss: 0.3601\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 126 Train Accuracy: 0.6861\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 126 Test Accuracy: 0.5320\n",
      "Epoch 126/500, Train Loss: 0.2115, Test Loss: 0.3596\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 127 Train Accuracy: 0.6667\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 127 Test Accuracy: 0.5387\n",
      "Epoch 127/500, Train Loss: 0.2066, Test Loss: 0.3733\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 128 Train Accuracy: 0.6633\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 128 Test Accuracy: 0.5421\n",
      "Epoch 128/500, Train Loss: 0.2096, Test Loss: 0.3889\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 129 Train Accuracy: 0.6937\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 129 Test Accuracy: 0.5455\n",
      "Epoch 129/500, Train Loss: 0.2090, Test Loss: 0.3980\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 130 Train Accuracy: 0.6987\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 130 Test Accuracy: 0.5421\n",
      "Epoch 130/500, Train Loss: 0.1926, Test Loss: 0.3901\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 131 Train Accuracy: 0.7013\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 131 Test Accuracy: 0.5387\n",
      "Epoch 131/500, Train Loss: 0.2022, Test Loss: 0.3910\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 132 Train Accuracy: 0.7105\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 132 Test Accuracy: 0.5387\n",
      "Epoch 132/500, Train Loss: 0.2023, Test Loss: 0.3751\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 133 Train Accuracy: 0.6751\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 133 Test Accuracy: 0.5185\n",
      "Epoch 133/500, Train Loss: 0.2068, Test Loss: 0.4249\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 134 Train Accuracy: 0.7367\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 134 Test Accuracy: 0.5354\n",
      "Epoch 134/500, Train Loss: 0.1824, Test Loss: 0.4084\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 135 Train Accuracy: 0.7063\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 135 Test Accuracy: 0.5354\n",
      "Epoch 135/500, Train Loss: 0.1984, Test Loss: 0.3800\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 136 Train Accuracy: 0.7468\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 136 Test Accuracy: 0.5286\n",
      "Epoch 136/500, Train Loss: 0.1792, Test Loss: 0.4550\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 137 Train Accuracy: 0.6844\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 137 Test Accuracy: 0.5219\n",
      "Epoch 137/500, Train Loss: 0.1986, Test Loss: 0.4291\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Epoch 138 Train Accuracy: 0.7274\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 138 Test Accuracy: 0.5286\n",
      "Epoch 138/500, Train Loss: 0.1757, Test Loss: 0.4603\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 139 Train Accuracy: 0.7207\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 139 Test Accuracy: 0.5320\n",
      "Epoch 139/500, Train Loss: 0.1928, Test Loss: 0.4201\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 140 Train Accuracy: 0.7333\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 140 Test Accuracy: 0.5219\n",
      "Epoch 140/500, Train Loss: 0.1908, Test Loss: 0.4832\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 141 Train Accuracy: 0.7359\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 141 Test Accuracy: 0.5320\n",
      "Epoch 141/500, Train Loss: 0.1885, Test Loss: 0.3953\n",
      "Train Preds: tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 142 Train Accuracy: 0.7139\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 142 Test Accuracy: 0.5185\n",
      "Epoch 142/500, Train Loss: 0.1949, Test Loss: 0.4562\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Epoch 143 Train Accuracy: 0.7046\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 143 Test Accuracy: 0.5185\n",
      "Epoch 143/500, Train Loss: 0.2042, Test Loss: 0.4645\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 144 Train Accuracy: 0.7038\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 144 Test Accuracy: 0.5320\n",
      "Epoch 144/500, Train Loss: 0.1999, Test Loss: 0.5201\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 145 Train Accuracy: 0.7291\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 145 Test Accuracy: 0.5320\n",
      "Epoch 145/500, Train Loss: 0.1890, Test Loss: 0.4299\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 146 Train Accuracy: 0.7316\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 146 Test Accuracy: 0.5387\n",
      "Epoch 146/500, Train Loss: 0.1813, Test Loss: 0.5409\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 147 Train Accuracy: 0.7586\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 147 Test Accuracy: 0.5219\n",
      "Epoch 147/500, Train Loss: 0.1673, Test Loss: 0.6664\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 148 Train Accuracy: 0.7249\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 148 Test Accuracy: 0.5589\n",
      "Epoch 148/500, Train Loss: 0.1850, Test Loss: 0.6624\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Epoch 149 Train Accuracy: 0.7131\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 149 Test Accuracy: 0.5488\n",
      "Epoch 149/500, Train Loss: 0.1860, Test Loss: 0.6887\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 150 Train Accuracy: 0.7308\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 150 Test Accuracy: 0.5421\n",
      "Epoch 150/500, Train Loss: 0.1902, Test Loss: 0.5920\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 151 Train Accuracy: 0.7435\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 151 Test Accuracy: 0.5354\n",
      "Epoch 151/500, Train Loss: 0.1755, Test Loss: 0.6042\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 152 Train Accuracy: 0.7401\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 152 Test Accuracy: 0.5623\n",
      "Epoch 152/500, Train Loss: 0.1782, Test Loss: 0.7286\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 153 Train Accuracy: 0.7409\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 153 Test Accuracy: 0.5320\n",
      "Epoch 153/500, Train Loss: 0.1747, Test Loss: 0.7259\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 154 Train Accuracy: 0.7207\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 154 Test Accuracy: 0.5387\n",
      "Epoch 154/500, Train Loss: 0.1865, Test Loss: 0.5374\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 155 Train Accuracy: 0.7527\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 155 Test Accuracy: 0.5253\n",
      "Epoch 155/500, Train Loss: 0.1753, Test Loss: 0.6827\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 156 Train Accuracy: 0.7283\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 156 Test Accuracy: 0.5387\n",
      "Epoch 156/500, Train Loss: 0.1829, Test Loss: 0.5551\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 0., 1., 1., 1.])\n",
      "Epoch 157 Train Accuracy: 0.7561\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 157 Test Accuracy: 0.5387\n",
      "Epoch 157/500, Train Loss: 0.1747, Test Loss: 0.5053\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 158 Train Accuracy: 0.7705\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 158 Test Accuracy: 0.5286\n",
      "Epoch 158/500, Train Loss: 0.1609, Test Loss: 0.3926\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 159 Train Accuracy: 0.7342\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 159 Test Accuracy: 0.5421\n",
      "Epoch 159/500, Train Loss: 0.1801, Test Loss: 0.6214\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 160 Train Accuracy: 0.7797\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 160 Test Accuracy: 0.5320\n",
      "Epoch 160/500, Train Loss: 0.1592, Test Loss: 0.5711\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 161 Train Accuracy: 0.7570\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 161 Test Accuracy: 0.5421\n",
      "Epoch 161/500, Train Loss: 0.1680, Test Loss: 0.6763\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Epoch 162 Train Accuracy: 0.7764\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 162 Test Accuracy: 0.5421\n",
      "Epoch 162/500, Train Loss: 0.1589, Test Loss: 0.6860\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 163 Train Accuracy: 0.7409\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 163 Test Accuracy: 0.5387\n",
      "Epoch 163/500, Train Loss: 0.1800, Test Loss: 0.5034\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 164 Train Accuracy: 0.7468\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 164 Test Accuracy: 0.5455\n",
      "Epoch 164/500, Train Loss: 0.1764, Test Loss: 0.5792\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 165 Train Accuracy: 0.7316\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 165 Test Accuracy: 0.5421\n",
      "Epoch 165/500, Train Loss: 0.1836, Test Loss: 0.7721\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 166 Train Accuracy: 0.7536\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 166 Test Accuracy: 0.5387\n",
      "Epoch 166/500, Train Loss: 0.1710, Test Loss: 0.7680\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 167 Train Accuracy: 0.7527\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 167 Test Accuracy: 0.5960\n",
      "Epoch 167/500, Train Loss: 0.1767, Test Loss: 1.0917\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "Epoch 168 Train Accuracy: 0.7578\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 168 Test Accuracy: 0.5387\n",
      "Epoch 168/500, Train Loss: 0.1730, Test Loss: 0.5726\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "Epoch 169 Train Accuracy: 0.7612\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 169 Test Accuracy: 0.5387\n",
      "Epoch 169/500, Train Loss: 0.1641, Test Loss: 0.8183\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 170 Train Accuracy: 0.7772\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 170 Test Accuracy: 0.5556\n",
      "Epoch 170/500, Train Loss: 0.1572, Test Loss: 0.8666\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 171 Train Accuracy: 0.7806\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 171 Test Accuracy: 0.5387\n",
      "Epoch 171/500, Train Loss: 0.1495, Test Loss: 0.5111\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 172 Train Accuracy: 0.7747\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 172 Test Accuracy: 0.5657\n",
      "Epoch 172/500, Train Loss: 0.1645, Test Loss: 0.8071\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 173 Train Accuracy: 0.7688\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 173 Test Accuracy: 0.5657\n",
      "Epoch 173/500, Train Loss: 0.1641, Test Loss: 0.8253\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 174 Train Accuracy: 0.7688\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 174 Test Accuracy: 0.5825\n",
      "Epoch 174/500, Train Loss: 0.1757, Test Loss: 1.0114\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 175 Train Accuracy: 0.7662\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 175 Test Accuracy: 0.5960\n",
      "Epoch 175/500, Train Loss: 0.1705, Test Loss: 1.0544\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 176 Train Accuracy: 0.7654\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 176 Test Accuracy: 0.5556\n",
      "Epoch 176/500, Train Loss: 0.1614, Test Loss: 0.9383\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 177 Train Accuracy: 0.7806\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 177 Test Accuracy: 0.5926\n",
      "Epoch 177/500, Train Loss: 0.1582, Test Loss: 0.9943\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 178 Train Accuracy: 0.7806\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 178 Test Accuracy: 0.5724\n",
      "Epoch 178/500, Train Loss: 0.1564, Test Loss: 0.9781\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "Epoch 179 Train Accuracy: 0.7730\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 179 Test Accuracy: 0.5892\n",
      "Epoch 179/500, Train Loss: 0.1562, Test Loss: 1.0661\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 180 Train Accuracy: 0.7637\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 180 Test Accuracy: 0.6061\n",
      "Epoch 180/500, Train Loss: 0.1566, Test Loss: 1.2013\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 181 Train Accuracy: 0.7873\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 181 Test Accuracy: 0.5522\n",
      "Epoch 181/500, Train Loss: 0.1533, Test Loss: 0.7182\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Epoch 182 Train Accuracy: 0.7502\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 182 Test Accuracy: 0.5758\n",
      "Epoch 182/500, Train Loss: 0.1665, Test Loss: 0.7649\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 183 Train Accuracy: 0.7646\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 183 Test Accuracy: 0.5960\n",
      "Epoch 183/500, Train Loss: 0.1602, Test Loss: 1.0632\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Epoch 184 Train Accuracy: 0.7755\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 184 Test Accuracy: 0.6027\n",
      "Epoch 184/500, Train Loss: 0.1510, Test Loss: 0.9190\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 185 Train Accuracy: 0.7823\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 185 Test Accuracy: 0.5488\n",
      "Epoch 185/500, Train Loss: 0.1634, Test Loss: 0.6681\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 186 Train Accuracy: 0.7966\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 186 Test Accuracy: 0.5892\n",
      "Epoch 186/500, Train Loss: 0.1501, Test Loss: 0.7768\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 187 Train Accuracy: 0.7924\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 187 Test Accuracy: 0.5387\n",
      "Epoch 187/500, Train Loss: 0.1559, Test Loss: 0.6417\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 188 Train Accuracy: 0.7747\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 188 Test Accuracy: 0.5455\n",
      "Epoch 188/500, Train Loss: 0.1572, Test Loss: 0.4973\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 189 Train Accuracy: 0.7781\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 189 Test Accuracy: 0.5758\n",
      "Epoch 189/500, Train Loss: 0.1594, Test Loss: 0.7747\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 190 Train Accuracy: 0.7924\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 190 Test Accuracy: 0.6061\n",
      "Epoch 190/500, Train Loss: 0.1585, Test Loss: 0.9658\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 191 Train Accuracy: 0.7797\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 191 Test Accuracy: 0.5791\n",
      "Epoch 191/500, Train Loss: 0.1471, Test Loss: 0.9282\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 192 Train Accuracy: 0.7907\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 192 Test Accuracy: 0.5556\n",
      "Epoch 192/500, Train Loss: 0.1588, Test Loss: 0.6827\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 193 Train Accuracy: 0.7823\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 193 Test Accuracy: 0.6128\n",
      "Epoch 193/500, Train Loss: 0.1463, Test Loss: 1.0760\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 194 Train Accuracy: 0.8321\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 194 Test Accuracy: 0.6195\n",
      "Epoch 194/500, Train Loss: 0.1293, Test Loss: 1.1269\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 195 Train Accuracy: 0.7823\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 195 Test Accuracy: 0.6061\n",
      "Epoch 195/500, Train Loss: 0.1527, Test Loss: 1.0006\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 196 Train Accuracy: 0.7755\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 196 Test Accuracy: 0.6128\n",
      "Epoch 196/500, Train Loss: 0.1570, Test Loss: 1.0483\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 197 Train Accuracy: 0.7907\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 197 Test Accuracy: 0.6162\n",
      "Epoch 197/500, Train Loss: 0.1466, Test Loss: 0.9342\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 198 Train Accuracy: 0.7899\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 198 Test Accuracy: 0.5993\n",
      "Epoch 198/500, Train Loss: 0.1542, Test Loss: 0.8839\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 199 Train Accuracy: 0.7865\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 199 Test Accuracy: 0.6532\n",
      "Epoch 199/500, Train Loss: 0.1613, Test Loss: 1.3006\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 200 Train Accuracy: 0.8135\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 200 Test Accuracy: 0.5690\n",
      "Epoch 200/500, Train Loss: 0.1297, Test Loss: 0.6592\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 201 Train Accuracy: 0.7848\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 201 Test Accuracy: 0.6229\n",
      "Epoch 201/500, Train Loss: 0.1557, Test Loss: 1.2250\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 202 Train Accuracy: 0.8186\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 202 Test Accuracy: 0.6330\n",
      "Epoch 202/500, Train Loss: 0.1370, Test Loss: 1.2269\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 203 Train Accuracy: 0.7983\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 203 Test Accuracy: 0.6195\n",
      "Epoch 203/500, Train Loss: 0.1467, Test Loss: 1.0665\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 204 Train Accuracy: 0.8236\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 204 Test Accuracy: 0.5253\n",
      "Epoch 204/500, Train Loss: 0.1303, Test Loss: 0.4230\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 205 Train Accuracy: 0.7738\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 205 Test Accuracy: 0.6296\n",
      "Epoch 205/500, Train Loss: 0.1590, Test Loss: 1.1182\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 206 Train Accuracy: 0.8127\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 206 Test Accuracy: 0.6296\n",
      "Epoch 206/500, Train Loss: 0.1323, Test Loss: 0.9975\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 207 Train Accuracy: 0.8143\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 207 Test Accuracy: 0.5993\n",
      "Epoch 207/500, Train Loss: 0.1313, Test Loss: 0.7261\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 208 Train Accuracy: 0.8025\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 208 Test Accuracy: 0.6195\n",
      "Epoch 208/500, Train Loss: 0.1393, Test Loss: 0.8321\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 209 Train Accuracy: 0.7907\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 209 Test Accuracy: 0.6263\n",
      "Epoch 209/500, Train Loss: 0.1418, Test Loss: 1.1381\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 210 Train Accuracy: 0.7831\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 210 Test Accuracy: 0.6027\n",
      "Epoch 210/500, Train Loss: 0.1458, Test Loss: 0.7595\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 211 Train Accuracy: 0.8169\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 211 Test Accuracy: 0.6229\n",
      "Epoch 211/500, Train Loss: 0.1335, Test Loss: 0.9493\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 212 Train Accuracy: 0.8371\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 212 Test Accuracy: 0.6431\n",
      "Epoch 212/500, Train Loss: 0.1367, Test Loss: 1.1897\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 213 Train Accuracy: 0.7941\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 213 Test Accuracy: 0.5993\n",
      "Epoch 213/500, Train Loss: 0.1409, Test Loss: 0.6028\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 214 Train Accuracy: 0.8346\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 214 Test Accuracy: 0.6330\n",
      "Epoch 214/500, Train Loss: 0.1233, Test Loss: 0.6199\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 215 Train Accuracy: 0.8042\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 215 Test Accuracy: 0.6364\n",
      "Epoch 215/500, Train Loss: 0.1402, Test Loss: 0.7550\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 216 Train Accuracy: 0.8371\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 216 Test Accuracy: 0.5354\n",
      "Epoch 216/500, Train Loss: 0.1398, Test Loss: 0.4826\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 217 Train Accuracy: 0.8574\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 217 Test Accuracy: 0.6835\n",
      "Epoch 217/500, Train Loss: 0.1189, Test Loss: 1.0008\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 218 Train Accuracy: 0.8262\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 218 Test Accuracy: 0.6162\n",
      "Epoch 218/500, Train Loss: 0.1413, Test Loss: 0.7367\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 219 Train Accuracy: 0.8025\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 219 Test Accuracy: 0.5892\n",
      "Epoch 219/500, Train Loss: 0.1368, Test Loss: 0.5906\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 220 Train Accuracy: 0.8203\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 220 Test Accuracy: 0.6498\n",
      "Epoch 220/500, Train Loss: 0.1327, Test Loss: 0.8982\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 221 Train Accuracy: 0.8278\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 221 Test Accuracy: 0.5926\n",
      "Epoch 221/500, Train Loss: 0.1530, Test Loss: 0.6935\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 222 Train Accuracy: 0.8135\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 222 Test Accuracy: 0.5421\n",
      "Epoch 222/500, Train Loss: 0.1404, Test Loss: 0.4986\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 223 Train Accuracy: 0.8312\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 223 Test Accuracy: 0.6566\n",
      "Epoch 223/500, Train Loss: 0.1229, Test Loss: 0.9753\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 224 Train Accuracy: 0.7932\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 224 Test Accuracy: 0.6532\n",
      "Epoch 224/500, Train Loss: 0.1361, Test Loss: 0.9689\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 225 Train Accuracy: 0.7983\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 225 Test Accuracy: 0.6465\n",
      "Epoch 225/500, Train Loss: 0.1454, Test Loss: 0.6225\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 226 Train Accuracy: 0.8422\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 226 Test Accuracy: 0.6330\n",
      "Epoch 226/500, Train Loss: 0.1147, Test Loss: 0.7237\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 227 Train Accuracy: 0.8194\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 227 Test Accuracy: 0.6263\n",
      "Epoch 227/500, Train Loss: 0.1368, Test Loss: 0.6829\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 228 Train Accuracy: 0.8093\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 228 Test Accuracy: 0.6027\n",
      "Epoch 228/500, Train Loss: 0.1381, Test Loss: 0.5111\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 229 Train Accuracy: 0.8278\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 229 Test Accuracy: 0.6431\n",
      "Epoch 229/500, Train Loss: 0.1275, Test Loss: 0.7560\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 230 Train Accuracy: 0.8380\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 230 Test Accuracy: 0.6162\n",
      "Epoch 230/500, Train Loss: 0.1260, Test Loss: 0.4606\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 231 Train Accuracy: 0.7916\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 231 Test Accuracy: 0.6465\n",
      "Epoch 231/500, Train Loss: 0.1495, Test Loss: 0.5101\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 232 Train Accuracy: 0.8321\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 232 Test Accuracy: 0.6397\n",
      "Epoch 232/500, Train Loss: 0.1264, Test Loss: 0.6406\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 233 Train Accuracy: 0.8414\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 233 Test Accuracy: 0.6633\n",
      "Epoch 233/500, Train Loss: 0.1176, Test Loss: 0.6967\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 234 Train Accuracy: 0.7916\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 234 Test Accuracy: 0.6566\n",
      "Epoch 234/500, Train Loss: 0.1407, Test Loss: 0.6730\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 235 Train Accuracy: 0.8329\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 235 Test Accuracy: 0.6397\n",
      "Epoch 235/500, Train Loss: 0.1281, Test Loss: 0.5953\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 236 Train Accuracy: 0.8203\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 236 Test Accuracy: 0.6330\n",
      "Epoch 236/500, Train Loss: 0.1407, Test Loss: 0.5116\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Epoch 237 Train Accuracy: 0.8295\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 237 Test Accuracy: 0.6532\n",
      "Epoch 237/500, Train Loss: 0.1383, Test Loss: 0.4840\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 238 Train Accuracy: 0.8203\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 238 Test Accuracy: 0.5320\n",
      "Epoch 238/500, Train Loss: 0.1327, Test Loss: 0.3560\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 239 Train Accuracy: 0.8464\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 239 Test Accuracy: 0.6700\n",
      "Epoch 239/500, Train Loss: 0.1117, Test Loss: 0.6988\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 240 Train Accuracy: 0.8278\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 240 Test Accuracy: 0.6936\n",
      "Epoch 240/500, Train Loss: 0.1219, Test Loss: 0.8927\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 241 Train Accuracy: 0.8329\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 241 Test Accuracy: 0.6431\n",
      "Epoch 241/500, Train Loss: 0.1270, Test Loss: 0.5235\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Epoch 242 Train Accuracy: 0.8093\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 242 Test Accuracy: 0.5859\n",
      "Epoch 242/500, Train Loss: 0.1379, Test Loss: 0.3912\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 243 Train Accuracy: 0.8245\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 243 Test Accuracy: 0.5960\n",
      "Epoch 243/500, Train Loss: 0.1328, Test Loss: 0.4195\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Epoch 244 Train Accuracy: 0.8245\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 244 Test Accuracy: 0.5623\n",
      "Epoch 244/500, Train Loss: 0.1446, Test Loss: 0.4077\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 245 Train Accuracy: 0.8262\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 245 Test Accuracy: 0.6364\n",
      "Epoch 245/500, Train Loss: 0.1287, Test Loss: 0.4422\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 246 Train Accuracy: 0.8236\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 246 Test Accuracy: 0.5892\n",
      "Epoch 246/500, Train Loss: 0.1312, Test Loss: 0.3759\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 247 Train Accuracy: 0.8473\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 247 Test Accuracy: 0.6970\n",
      "Epoch 247/500, Train Loss: 0.1255, Test Loss: 0.7018\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 248 Train Accuracy: 0.8346\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 248 Test Accuracy: 0.6633\n",
      "Epoch 248/500, Train Loss: 0.1211, Test Loss: 0.4761\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 249 Train Accuracy: 0.8354\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 249 Test Accuracy: 0.6936\n",
      "Epoch 249/500, Train Loss: 0.1239, Test Loss: 0.5522\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 250 Train Accuracy: 0.8641\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 250 Test Accuracy: 0.6667\n",
      "Epoch 250/500, Train Loss: 0.1118, Test Loss: 0.5232\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 251 Train Accuracy: 0.8464\n",
      "Test Preds: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 251 Test Accuracy: 0.6330\n",
      "Epoch 251/500, Train Loss: 0.1105, Test Loss: 0.4648\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 252 Train Accuracy: 0.8464\n",
      "Test Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 252 Test Accuracy: 0.6801\n",
      "Epoch 252/500, Train Loss: 0.1195, Test Loss: 0.5232\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 253 Train Accuracy: 0.8135\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 253 Test Accuracy: 0.5320\n",
      "Epoch 253/500, Train Loss: 0.1447, Test Loss: 0.3021\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 254 Train Accuracy: 0.8219\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 254 Test Accuracy: 0.5724\n",
      "Epoch 254/500, Train Loss: 0.1287, Test Loss: 0.2695\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 255 Train Accuracy: 0.8287\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 255 Test Accuracy: 0.6700\n",
      "Epoch 255/500, Train Loss: 0.1244, Test Loss: 0.3363\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 256 Train Accuracy: 0.8489\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 256 Test Accuracy: 0.6397\n",
      "Epoch 256/500, Train Loss: 0.1160, Test Loss: 0.3530\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 257 Train Accuracy: 0.8346\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 257 Test Accuracy: 0.5589\n",
      "Epoch 257/500, Train Loss: 0.1227, Test Loss: 0.2545\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 258 Train Accuracy: 0.8464\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 258 Test Accuracy: 0.7273\n",
      "Epoch 258/500, Train Loss: 0.1139, Test Loss: 0.3439\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 259 Train Accuracy: 0.8473\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 259 Test Accuracy: 0.5522\n",
      "Epoch 259/500, Train Loss: 0.1141, Test Loss: 0.2869\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 260 Train Accuracy: 0.8025\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 260 Test Accuracy: 0.7003\n",
      "Epoch 260/500, Train Loss: 0.1345, Test Loss: 0.2716\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 261 Train Accuracy: 0.8549\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 261 Test Accuracy: 0.5825\n",
      "Epoch 261/500, Train Loss: 0.1164, Test Loss: 0.2606\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 262 Train Accuracy: 0.8574\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 262 Test Accuracy: 0.7205\n",
      "Epoch 262/500, Train Loss: 0.1132, Test Loss: 0.3144\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 263 Train Accuracy: 0.8380\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 263 Test Accuracy: 0.7003\n",
      "Epoch 263/500, Train Loss: 0.1159, Test Loss: 0.3978\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 264 Train Accuracy: 0.8338\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 264 Test Accuracy: 0.6667\n",
      "Epoch 264/500, Train Loss: 0.1180, Test Loss: 0.2747\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 265 Train Accuracy: 0.8262\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 265 Test Accuracy: 0.8114\n",
      "Epoch 265/500, Train Loss: 0.1248, Test Loss: 0.2360\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 266 Train Accuracy: 0.8219\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 266 Test Accuracy: 0.6835\n",
      "Epoch 266/500, Train Loss: 0.1232, Test Loss: 0.2398\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 267 Train Accuracy: 0.8414\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 267 Test Accuracy: 0.8013\n",
      "Epoch 267/500, Train Loss: 0.1109, Test Loss: 0.2492\n",
      "Train Preds: tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 268 Train Accuracy: 0.8219\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 268 Test Accuracy: 0.6936\n",
      "Epoch 268/500, Train Loss: 0.1267, Test Loss: 0.2622\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 269 Train Accuracy: 0.8481\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 269 Test Accuracy: 0.5152\n",
      "Epoch 269/500, Train Loss: 0.1286, Test Loss: 0.2929\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 270 Train Accuracy: 0.8498\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 270 Test Accuracy: 0.8182\n",
      "Epoch 270/500, Train Loss: 0.1111, Test Loss: 0.2781\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 271 Train Accuracy: 0.8599\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 271 Test Accuracy: 0.7542\n",
      "Epoch 271/500, Train Loss: 0.1036, Test Loss: 0.3670\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 272 Train Accuracy: 0.8692\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 272 Test Accuracy: 0.7677\n",
      "Epoch 272/500, Train Loss: 0.1125, Test Loss: 0.2565\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 273 Train Accuracy: 0.8354\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 273 Test Accuracy: 0.6498\n",
      "Epoch 273/500, Train Loss: 0.1203, Test Loss: 0.2602\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 274 Train Accuracy: 0.8397\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 274 Test Accuracy: 0.6902\n",
      "Epoch 274/500, Train Loss: 0.1176, Test Loss: 0.2226\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 275 Train Accuracy: 0.8346\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 275 Test Accuracy: 0.5522\n",
      "Epoch 275/500, Train Loss: 0.1268, Test Loss: 0.2123\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 276 Train Accuracy: 0.8430\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 276 Test Accuracy: 0.6566\n",
      "Epoch 276/500, Train Loss: 0.1126, Test Loss: 0.2202\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 277 Train Accuracy: 0.8473\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 277 Test Accuracy: 0.7677\n",
      "Epoch 277/500, Train Loss: 0.1209, Test Loss: 0.1611\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 278 Train Accuracy: 0.8498\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 278 Test Accuracy: 0.7239\n",
      "Epoch 278/500, Train Loss: 0.1056, Test Loss: 0.2048\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 279 Train Accuracy: 0.8650\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 279 Test Accuracy: 0.8215\n",
      "Epoch 279/500, Train Loss: 0.1022, Test Loss: 0.1803\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 280 Train Accuracy: 0.8473\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 280 Test Accuracy: 0.7475\n",
      "Epoch 280/500, Train Loss: 0.1101, Test Loss: 0.2039\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 281 Train Accuracy: 0.8591\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 281 Test Accuracy: 0.8418\n",
      "Epoch 281/500, Train Loss: 0.1051, Test Loss: 0.2260\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "Epoch 282 Train Accuracy: 0.8321\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 282 Test Accuracy: 0.7071\n",
      "Epoch 282/500, Train Loss: 0.1161, Test Loss: 0.1834\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "Epoch 283 Train Accuracy: 0.8464\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 283 Test Accuracy: 0.8148\n",
      "Epoch 283/500, Train Loss: 0.1204, Test Loss: 0.2064\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 284 Train Accuracy: 0.8481\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 284 Test Accuracy: 0.5387\n",
      "Epoch 284/500, Train Loss: 0.1188, Test Loss: 0.2203\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 285 Train Accuracy: 0.8641\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 285 Test Accuracy: 0.7340\n",
      "Epoch 285/500, Train Loss: 0.1001, Test Loss: 0.1989\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 286 Train Accuracy: 0.8532\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 286 Test Accuracy: 0.7441\n",
      "Epoch 286/500, Train Loss: 0.1208, Test Loss: 0.1782\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 287 Train Accuracy: 0.8692\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 287 Test Accuracy: 0.7845\n",
      "Epoch 287/500, Train Loss: 0.1001, Test Loss: 0.1740\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 288 Train Accuracy: 0.8498\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 288 Test Accuracy: 0.8451\n",
      "Epoch 288/500, Train Loss: 0.1196, Test Loss: 0.1933\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 289 Train Accuracy: 0.8549\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 289 Test Accuracy: 0.8283\n",
      "Epoch 289/500, Train Loss: 0.1260, Test Loss: 0.1689\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 290 Train Accuracy: 0.8456\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 290 Test Accuracy: 0.8047\n",
      "Epoch 290/500, Train Loss: 0.1090, Test Loss: 0.1475\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 291 Train Accuracy: 0.8549\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 291 Test Accuracy: 0.8653\n",
      "Epoch 291/500, Train Loss: 0.1069, Test Loss: 0.1219\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 292 Train Accuracy: 0.8498\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 292 Test Accuracy: 0.9024\n",
      "Epoch 292/500, Train Loss: 0.1093, Test Loss: 0.1687\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 293 Train Accuracy: 0.8878\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 293 Test Accuracy: 0.7542\n",
      "Epoch 293/500, Train Loss: 0.0895, Test Loss: 0.1587\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 294 Train Accuracy: 0.8776\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 294 Test Accuracy: 0.8316\n",
      "Epoch 294/500, Train Loss: 0.1020, Test Loss: 0.1616\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 295 Train Accuracy: 0.8759\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 295 Test Accuracy: 0.9259\n",
      "Epoch 295/500, Train Loss: 0.1026, Test Loss: 0.0975\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 296 Train Accuracy: 0.8624\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 296 Test Accuracy: 0.9125\n",
      "Epoch 296/500, Train Loss: 0.1067, Test Loss: 0.1179\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 297 Train Accuracy: 0.8616\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 297 Test Accuracy: 0.9360\n",
      "Epoch 297/500, Train Loss: 0.1053, Test Loss: 0.1014\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 298 Train Accuracy: 0.8574\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 298 Test Accuracy: 0.6498\n",
      "Epoch 298/500, Train Loss: 0.1183, Test Loss: 0.2003\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Epoch 299 Train Accuracy: 0.8481\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 299 Test Accuracy: 0.9158\n",
      "Epoch 299/500, Train Loss: 0.1201, Test Loss: 0.0929\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 300 Train Accuracy: 0.8734\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 300 Test Accuracy: 0.9259\n",
      "Epoch 300/500, Train Loss: 0.1095, Test Loss: 0.0788\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Epoch 301 Train Accuracy: 0.8481\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 301 Test Accuracy: 0.5387\n",
      "Epoch 301/500, Train Loss: 0.1195, Test Loss: 0.2844\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 302 Train Accuracy: 0.8354\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 302 Test Accuracy: 0.6195\n",
      "Epoch 302/500, Train Loss: 0.1173, Test Loss: 0.1865\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 303 Train Accuracy: 0.8810\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 303 Test Accuracy: 0.8889\n",
      "Epoch 303/500, Train Loss: 0.0996, Test Loss: 0.1111\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 304 Train Accuracy: 0.8582\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 304 Test Accuracy: 0.9562\n",
      "Epoch 304/500, Train Loss: 0.1133, Test Loss: 0.0674\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 305 Train Accuracy: 0.8549\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 305 Test Accuracy: 0.9226\n",
      "Epoch 305/500, Train Loss: 0.1105, Test Loss: 0.1072\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 306 Train Accuracy: 0.8608\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 306 Test Accuracy: 0.7609\n",
      "Epoch 306/500, Train Loss: 0.1001, Test Loss: 0.1388\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 307 Train Accuracy: 0.8591\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 307 Test Accuracy: 0.6465\n",
      "Epoch 307/500, Train Loss: 0.1091, Test Loss: 0.1574\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 308 Train Accuracy: 0.8869\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 308 Test Accuracy: 0.9293\n",
      "Epoch 308/500, Train Loss: 0.0904, Test Loss: 0.0959\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Epoch 309 Train Accuracy: 0.8608\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 309 Test Accuracy: 0.7845\n",
      "Epoch 309/500, Train Loss: 0.1056, Test Loss: 0.1374\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 310 Train Accuracy: 0.8928\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 310 Test Accuracy: 0.9630\n",
      "Epoch 310/500, Train Loss: 0.0926, Test Loss: 0.0527\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 311 Train Accuracy: 0.8802\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 311 Test Accuracy: 0.9259\n",
      "Epoch 311/500, Train Loss: 0.0946, Test Loss: 0.0901\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 312 Train Accuracy: 0.8473\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 312 Test Accuracy: 0.7710\n",
      "Epoch 312/500, Train Loss: 0.1073, Test Loss: 0.1355\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 313 Train Accuracy: 0.8658\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 313 Test Accuracy: 0.9057\n",
      "Epoch 313/500, Train Loss: 0.0996, Test Loss: 0.1117\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 314 Train Accuracy: 0.8726\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 314 Test Accuracy: 0.9360\n",
      "Epoch 314/500, Train Loss: 0.1127, Test Loss: 0.0846\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 315 Train Accuracy: 0.8515\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 315 Test Accuracy: 0.9327\n",
      "Epoch 315/500, Train Loss: 0.1117, Test Loss: 0.0875\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 1., 0., 1.])\n",
      "Epoch 316 Train Accuracy: 0.8608\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 316 Test Accuracy: 0.9226\n",
      "Epoch 316/500, Train Loss: 0.1023, Test Loss: 0.0899\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 317 Train Accuracy: 0.8591\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 317 Test Accuracy: 0.9562\n",
      "Epoch 317/500, Train Loss: 0.1018, Test Loss: 0.0678\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Epoch 318 Train Accuracy: 0.8785\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 318 Test Accuracy: 0.5825\n",
      "Epoch 318/500, Train Loss: 0.0916, Test Loss: 0.1726\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 319 Train Accuracy: 0.8810\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 319 Test Accuracy: 0.8148\n",
      "Epoch 319/500, Train Loss: 0.0956, Test Loss: 0.1326\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 320 Train Accuracy: 0.8456\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 320 Test Accuracy: 0.8923\n",
      "Epoch 320/500, Train Loss: 0.1135, Test Loss: 0.1065\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 321 Train Accuracy: 0.8835\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 321 Test Accuracy: 0.5690\n",
      "Epoch 321/500, Train Loss: 0.1204, Test Loss: 0.1878\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 322 Train Accuracy: 0.8549\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 322 Test Accuracy: 0.9697\n",
      "Epoch 322/500, Train Loss: 0.1189, Test Loss: 0.0444\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 323 Train Accuracy: 0.8751\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 323 Test Accuracy: 0.9024\n",
      "Epoch 323/500, Train Loss: 0.1015, Test Loss: 0.0947\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 324 Train Accuracy: 0.8456\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 324 Test Accuracy: 0.9697\n",
      "Epoch 324/500, Train Loss: 0.1122, Test Loss: 0.0492\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 325 Train Accuracy: 0.8979\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 325 Test Accuracy: 0.9327\n",
      "Epoch 325/500, Train Loss: 0.0953, Test Loss: 0.0788\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 326 Train Accuracy: 0.8962\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 326 Test Accuracy: 0.6532\n",
      "Epoch 326/500, Train Loss: 0.0884, Test Loss: 0.1762\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "Epoch 327 Train Accuracy: 0.8861\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 327 Test Accuracy: 0.8215\n",
      "Epoch 327/500, Train Loss: 0.0894, Test Loss: 0.1582\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 328 Train Accuracy: 0.8751\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 328 Test Accuracy: 0.8384\n",
      "Epoch 328/500, Train Loss: 0.0968, Test Loss: 0.1277\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Epoch 329 Train Accuracy: 0.8599\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 329 Test Accuracy: 0.7879\n",
      "Epoch 329/500, Train Loss: 0.1072, Test Loss: 0.1657\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 330 Train Accuracy: 0.8700\n",
      "Test Preds: tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 330 Test Accuracy: 0.8081\n",
      "Epoch 330/500, Train Loss: 0.0975, Test Loss: 0.2932\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "Epoch 331 Train Accuracy: 0.8641\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 331 Test Accuracy: 0.8923\n",
      "Epoch 331/500, Train Loss: 0.1115, Test Loss: 0.1133\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 332 Train Accuracy: 0.8751\n",
      "Test Preds: tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 332 Test Accuracy: 0.7845\n",
      "Epoch 332/500, Train Loss: 0.1071, Test Loss: 0.2230\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 333 Train Accuracy: 0.8861\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 333 Test Accuracy: 0.9259\n",
      "Epoch 333/500, Train Loss: 0.0874, Test Loss: 0.0643\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 334 Train Accuracy: 0.8464\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 334 Test Accuracy: 0.6970\n",
      "Epoch 334/500, Train Loss: 0.1082, Test Loss: 0.2076\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Epoch 335 Train Accuracy: 0.8599\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 335 Test Accuracy: 0.8485\n",
      "Epoch 335/500, Train Loss: 0.1058, Test Loss: 0.1457\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 336 Train Accuracy: 0.8979\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 336 Test Accuracy: 0.8148\n",
      "Epoch 336/500, Train Loss: 0.0865, Test Loss: 0.1720\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 337 Train Accuracy: 0.8819\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 337 Test Accuracy: 0.8114\n",
      "Epoch 337/500, Train Loss: 0.1111, Test Loss: 0.1808\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 338 Train Accuracy: 0.8591\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 338 Test Accuracy: 0.7980\n",
      "Epoch 338/500, Train Loss: 0.1083, Test Loss: 0.2574\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 339 Train Accuracy: 0.8616\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 339 Test Accuracy: 0.5589\n",
      "Epoch 339/500, Train Loss: 0.0978, Test Loss: 0.3567\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 340 Train Accuracy: 0.8920\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 340 Test Accuracy: 0.8485\n",
      "Epoch 340/500, Train Loss: 0.0917, Test Loss: 0.1581\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 341 Train Accuracy: 0.8684\n",
      "Test Preds: tensor([0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 341 Test Accuracy: 0.8081\n",
      "Epoch 341/500, Train Loss: 0.1147, Test Loss: 0.2099\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Epoch 342 Train Accuracy: 0.8329\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 342 Test Accuracy: 0.6869\n",
      "Epoch 342/500, Train Loss: 0.1281, Test Loss: 0.3307\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 343 Train Accuracy: 0.8785\n",
      "Test Preds: tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 343 Test Accuracy: 0.5657\n",
      "Epoch 343/500, Train Loss: 0.1019, Test Loss: 0.4242\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 344 Train Accuracy: 0.8574\n",
      "Test Preds: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 344 Test Accuracy: 0.8620\n",
      "Epoch 344/500, Train Loss: 0.1059, Test Loss: 0.1605\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 345 Train Accuracy: 0.8616\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 345 Test Accuracy: 0.7407\n",
      "Epoch 345/500, Train Loss: 0.1122, Test Loss: 0.2876\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 1.])\n",
      "Epoch 346 Train Accuracy: 0.8709\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 346 Test Accuracy: 0.7778\n",
      "Epoch 346/500, Train Loss: 0.1014, Test Loss: 0.3521\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 347 Train Accuracy: 0.8827\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 347 Test Accuracy: 0.7407\n",
      "Epoch 347/500, Train Loss: 0.0962, Test Loss: 0.3115\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 348 Train Accuracy: 0.8709\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 348 Test Accuracy: 0.5522\n",
      "Epoch 348/500, Train Loss: 0.0983, Test Loss: 0.3945\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 349 Train Accuracy: 0.9080\n",
      "Test Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 349 Test Accuracy: 0.5589\n",
      "Epoch 349/500, Train Loss: 0.0822, Test Loss: 0.3572\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 350 Train Accuracy: 0.8886\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 350 Test Accuracy: 0.8013\n",
      "Epoch 350/500, Train Loss: 0.0935, Test Loss: 0.2973\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 351 Train Accuracy: 0.8852\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 351 Test Accuracy: 0.7778\n",
      "Epoch 351/500, Train Loss: 0.0956, Test Loss: 0.2717\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 352 Train Accuracy: 0.8532\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 352 Test Accuracy: 0.7340\n",
      "Epoch 352/500, Train Loss: 0.1082, Test Loss: 0.3593\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 353 Train Accuracy: 0.8861\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 353 Test Accuracy: 0.8215\n",
      "Epoch 353/500, Train Loss: 0.0969, Test Loss: 0.3549\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1.])\n",
      "Epoch 354 Train Accuracy: 0.8582\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 354 Test Accuracy: 0.6599\n",
      "Epoch 354/500, Train Loss: 0.1008, Test Loss: 0.5374\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 355 Train Accuracy: 0.8886\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 355 Test Accuracy: 0.7172\n",
      "Epoch 355/500, Train Loss: 0.1042, Test Loss: 0.4507\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 356 Train Accuracy: 0.8920\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 356 Test Accuracy: 0.6599\n",
      "Epoch 356/500, Train Loss: 0.0927, Test Loss: 0.5656\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 357 Train Accuracy: 0.9021\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 357 Test Accuracy: 0.7879\n",
      "Epoch 357/500, Train Loss: 0.0863, Test Loss: 0.2822\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 358 Train Accuracy: 0.8954\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 358 Test Accuracy: 0.7980\n",
      "Epoch 358/500, Train Loss: 0.0912, Test Loss: 0.2356\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 359 Train Accuracy: 0.8878\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 359 Test Accuracy: 0.7239\n",
      "Epoch 359/500, Train Loss: 0.0923, Test Loss: 0.4462\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 360 Train Accuracy: 0.8717\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 360 Test Accuracy: 0.8249\n",
      "Epoch 360/500, Train Loss: 0.1015, Test Loss: 0.2886\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 361 Train Accuracy: 0.8759\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 361 Test Accuracy: 0.7710\n",
      "Epoch 361/500, Train Loss: 0.0979, Test Loss: 0.4057\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 362 Train Accuracy: 0.8920\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 362 Test Accuracy: 0.8081\n",
      "Epoch 362/500, Train Loss: 0.0897, Test Loss: 0.2428\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 363 Train Accuracy: 0.8709\n",
      "Test Preds: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 363 Test Accuracy: 0.8552\n",
      "Epoch 363/500, Train Loss: 0.0955, Test Loss: 0.2001\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 364 Train Accuracy: 0.8895\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 364 Test Accuracy: 0.7542\n",
      "Epoch 364/500, Train Loss: 0.0886, Test Loss: 0.3607\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 365 Train Accuracy: 0.8793\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 365 Test Accuracy: 0.7710\n",
      "Epoch 365/500, Train Loss: 0.0890, Test Loss: 0.3665\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 366 Train Accuracy: 0.8979\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 366 Test Accuracy: 0.7475\n",
      "Epoch 366/500, Train Loss: 0.0791, Test Loss: 0.4763\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 367 Train Accuracy: 0.8692\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 367 Test Accuracy: 0.7475\n",
      "Epoch 367/500, Train Loss: 0.0987, Test Loss: 0.4351\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 368 Train Accuracy: 0.8852\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 368 Test Accuracy: 0.5623\n",
      "Epoch 368/500, Train Loss: 0.0974, Test Loss: 0.6377\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 369 Train Accuracy: 0.8608\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 369 Test Accuracy: 0.7273\n",
      "Epoch 369/500, Train Loss: 0.1109, Test Loss: 0.5637\n",
      "Train Preds: tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 370 Train Accuracy: 0.8895\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 370 Test Accuracy: 0.7475\n",
      "Epoch 370/500, Train Loss: 0.0883, Test Loss: 0.4672\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 371 Train Accuracy: 0.8920\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 371 Test Accuracy: 0.7643\n",
      "Epoch 371/500, Train Loss: 0.0968, Test Loss: 0.5907\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 372 Train Accuracy: 0.8869\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 372 Test Accuracy: 0.7576\n",
      "Epoch 372/500, Train Loss: 0.0900, Test Loss: 0.4745\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 373 Train Accuracy: 0.8911\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 373 Test Accuracy: 0.7508\n",
      "Epoch 373/500, Train Loss: 0.0898, Test Loss: 0.4347\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 374 Train Accuracy: 0.8835\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 374 Test Accuracy: 0.7879\n",
      "Epoch 374/500, Train Loss: 0.0927, Test Loss: 0.3975\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 375 Train Accuracy: 0.8844\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 375 Test Accuracy: 0.7778\n",
      "Epoch 375/500, Train Loss: 0.0911, Test Loss: 0.3911\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 376 Train Accuracy: 0.8937\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 376 Test Accuracy: 0.8013\n",
      "Epoch 376/500, Train Loss: 0.0846, Test Loss: 0.3950\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 377 Train Accuracy: 0.8895\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 377 Test Accuracy: 0.7374\n",
      "Epoch 377/500, Train Loss: 0.0927, Test Loss: 0.4620\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 378 Train Accuracy: 0.8776\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 378 Test Accuracy: 0.7744\n",
      "Epoch 378/500, Train Loss: 0.0921, Test Loss: 0.4126\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 379 Train Accuracy: 0.9063\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 379 Test Accuracy: 0.7778\n",
      "Epoch 379/500, Train Loss: 0.0804, Test Loss: 0.3773\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 380 Train Accuracy: 0.8844\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 380 Test Accuracy: 0.6061\n",
      "Epoch 380/500, Train Loss: 0.0853, Test Loss: 0.6260\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 381 Train Accuracy: 0.8827\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 381 Test Accuracy: 0.7980\n",
      "Epoch 381/500, Train Loss: 0.0964, Test Loss: 0.3795\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 382 Train Accuracy: 0.9030\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 382 Test Accuracy: 0.6869\n",
      "Epoch 382/500, Train Loss: 0.0796, Test Loss: 0.5381\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n",
      "Epoch 383 Train Accuracy: 0.9131\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 383 Test Accuracy: 0.6633\n",
      "Epoch 383/500, Train Loss: 0.1012, Test Loss: 0.7231\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 384 Train Accuracy: 0.8903\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 384 Test Accuracy: 0.6566\n",
      "Epoch 384/500, Train Loss: 0.0839, Test Loss: 0.9197\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 385 Train Accuracy: 0.8928\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 385 Test Accuracy: 0.6970\n",
      "Epoch 385/500, Train Loss: 0.0902, Test Loss: 0.8685\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 386 Train Accuracy: 0.8759\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 386 Test Accuracy: 0.6599\n",
      "Epoch 386/500, Train Loss: 0.1140, Test Loss: 0.7692\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 387 Train Accuracy: 0.8768\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 387 Test Accuracy: 0.6768\n",
      "Epoch 387/500, Train Loss: 0.1058, Test Loss: 0.9631\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 388 Train Accuracy: 0.8852\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 388 Test Accuracy: 0.6397\n",
      "Epoch 388/500, Train Loss: 0.0911, Test Loss: 1.1968\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 389 Train Accuracy: 0.8920\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 389 Test Accuracy: 0.6700\n",
      "Epoch 389/500, Train Loss: 0.0920, Test Loss: 1.0406\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 390 Train Accuracy: 0.9114\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 390 Test Accuracy: 0.6296\n",
      "Epoch 390/500, Train Loss: 0.0841, Test Loss: 0.9098\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 391 Train Accuracy: 0.8937\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 391 Test Accuracy: 0.6835\n",
      "Epoch 391/500, Train Loss: 0.0860, Test Loss: 1.0290\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 392 Train Accuracy: 0.9080\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 392 Test Accuracy: 0.7071\n",
      "Epoch 392/500, Train Loss: 0.0794, Test Loss: 1.1206\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 393 Train Accuracy: 0.9072\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 393 Test Accuracy: 0.5758\n",
      "Epoch 393/500, Train Loss: 0.1033, Test Loss: 0.9901\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 394 Train Accuracy: 0.8726\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 394 Test Accuracy: 0.6566\n",
      "Epoch 394/500, Train Loss: 0.0951, Test Loss: 1.0241\n",
      "Train Preds: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 395 Train Accuracy: 0.8743\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 395 Test Accuracy: 0.6364\n",
      "Epoch 395/500, Train Loss: 0.0948, Test Loss: 1.0114\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 396 Train Accuracy: 0.9105\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 396 Test Accuracy: 0.6633\n",
      "Epoch 396/500, Train Loss: 0.0786, Test Loss: 1.1305\n",
      "Train Preds: tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Epoch 397 Train Accuracy: 0.8743\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 397 Test Accuracy: 0.6936\n",
      "Epoch 397/500, Train Loss: 0.0980, Test Loss: 1.2123\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 398 Train Accuracy: 0.8979\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 398 Test Accuracy: 0.6633\n",
      "Epoch 398/500, Train Loss: 0.0897, Test Loss: 1.4684\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 399 Train Accuracy: 0.8903\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 399 Test Accuracy: 0.7037\n",
      "Epoch 399/500, Train Loss: 0.0820, Test Loss: 1.0982\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 400 Train Accuracy: 0.8743\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 400 Test Accuracy: 0.6801\n",
      "Epoch 400/500, Train Loss: 0.1053, Test Loss: 1.1881\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 401 Train Accuracy: 0.8920\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 401 Test Accuracy: 0.6364\n",
      "Epoch 401/500, Train Loss: 0.0858, Test Loss: 1.3295\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 402 Train Accuracy: 0.9139\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 402 Test Accuracy: 0.6263\n",
      "Epoch 402/500, Train Loss: 0.0809, Test Loss: 1.2716\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 403 Train Accuracy: 0.9072\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 403 Test Accuracy: 0.5488\n",
      "Epoch 403/500, Train Loss: 0.0788, Test Loss: 1.2728\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 404 Train Accuracy: 0.9080\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 404 Test Accuracy: 0.6599\n",
      "Epoch 404/500, Train Loss: 0.0909, Test Loss: 1.4323\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 405 Train Accuracy: 0.9013\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 405 Test Accuracy: 0.6195\n",
      "Epoch 405/500, Train Loss: 0.0835, Test Loss: 1.4599\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 406 Train Accuracy: 0.9089\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 406 Test Accuracy: 0.6532\n",
      "Epoch 406/500, Train Loss: 0.0802, Test Loss: 1.3583\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 407 Train Accuracy: 0.9038\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 407 Test Accuracy: 0.5960\n",
      "Epoch 407/500, Train Loss: 0.0782, Test Loss: 2.0764\n",
      "Train Preds: tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 408 Train Accuracy: 0.9080\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 408 Test Accuracy: 0.6397\n",
      "Epoch 408/500, Train Loss: 0.0885, Test Loss: 1.4938\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 409 Train Accuracy: 0.9013\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 409 Test Accuracy: 0.6734\n",
      "Epoch 409/500, Train Loss: 0.0929, Test Loss: 1.2580\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 410 Train Accuracy: 0.8802\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 410 Test Accuracy: 0.6263\n",
      "Epoch 410/500, Train Loss: 0.0916, Test Loss: 1.3083\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 411 Train Accuracy: 0.8979\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 411 Test Accuracy: 0.6667\n",
      "Epoch 411/500, Train Loss: 0.0860, Test Loss: 1.4457\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 412 Train Accuracy: 0.8827\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 412 Test Accuracy: 0.6364\n",
      "Epoch 412/500, Train Loss: 0.0943, Test Loss: 1.8050\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 413 Train Accuracy: 0.9004\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 413 Test Accuracy: 0.5758\n",
      "Epoch 413/500, Train Loss: 0.0912, Test Loss: 2.2127\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 414 Train Accuracy: 0.8937\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 414 Test Accuracy: 0.5589\n",
      "Epoch 414/500, Train Loss: 0.0961, Test Loss: 1.5923\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 415 Train Accuracy: 0.8945\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 415 Test Accuracy: 0.6633\n",
      "Epoch 415/500, Train Loss: 0.0917, Test Loss: 1.8265\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 416 Train Accuracy: 0.9063\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 416 Test Accuracy: 0.5993\n",
      "Epoch 416/500, Train Loss: 0.0776, Test Loss: 2.1869\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Epoch 417 Train Accuracy: 0.9097\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 417 Test Accuracy: 0.6633\n",
      "Epoch 417/500, Train Loss: 0.0729, Test Loss: 1.4661\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 418 Train Accuracy: 0.9004\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 418 Test Accuracy: 0.6397\n",
      "Epoch 418/500, Train Loss: 0.0860, Test Loss: 1.7337\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 419 Train Accuracy: 0.9004\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 419 Test Accuracy: 0.6364\n",
      "Epoch 419/500, Train Loss: 0.0796, Test Loss: 1.9412\n",
      "Train Preds: tensor([0., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 420 Train Accuracy: 0.9013\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 420 Test Accuracy: 0.5960\n",
      "Epoch 420/500, Train Loss: 0.0773, Test Loss: 2.1855\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 421 Train Accuracy: 0.9165\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 421 Test Accuracy: 0.5690\n",
      "Epoch 421/500, Train Loss: 0.0717, Test Loss: 2.4541\n",
      "Train Preds: tensor([0., 0., 1., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 422 Train Accuracy: 0.9013\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 422 Test Accuracy: 0.6128\n",
      "Epoch 422/500, Train Loss: 0.0867, Test Loss: 2.3414\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 423 Train Accuracy: 0.8911\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 423 Test Accuracy: 0.5926\n",
      "Epoch 423/500, Train Loss: 0.0929, Test Loss: 2.0870\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 424 Train Accuracy: 0.9165\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 424 Test Accuracy: 0.6195\n",
      "Epoch 424/500, Train Loss: 0.0791, Test Loss: 2.0958\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 425 Train Accuracy: 0.8878\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 425 Test Accuracy: 0.6397\n",
      "Epoch 425/500, Train Loss: 0.0888, Test Loss: 1.9601\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 426 Train Accuracy: 0.8962\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 426 Test Accuracy: 0.6195\n",
      "Epoch 426/500, Train Loss: 0.0812, Test Loss: 2.3438\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 427 Train Accuracy: 0.9224\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 427 Test Accuracy: 0.5286\n",
      "Epoch 427/500, Train Loss: 0.1098, Test Loss: 2.0791\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 428 Train Accuracy: 0.9105\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 428 Test Accuracy: 0.5758\n",
      "Epoch 428/500, Train Loss: 0.0772, Test Loss: 2.8435\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 429 Train Accuracy: 0.9291\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 429 Test Accuracy: 0.5859\n",
      "Epoch 429/500, Train Loss: 0.0690, Test Loss: 2.3441\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 430 Train Accuracy: 0.9274\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 430 Test Accuracy: 0.6027\n",
      "Epoch 430/500, Train Loss: 0.0681, Test Loss: 2.3821\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 431 Train Accuracy: 0.9131\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 431 Test Accuracy: 0.5556\n",
      "Epoch 431/500, Train Loss: 0.0911, Test Loss: 2.6627\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 432 Train Accuracy: 0.9063\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 432 Test Accuracy: 0.5791\n",
      "Epoch 432/500, Train Loss: 0.0902, Test Loss: 2.7339\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 433 Train Accuracy: 0.9055\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 433 Test Accuracy: 0.6229\n",
      "Epoch 433/500, Train Loss: 0.0852, Test Loss: 2.0895\n",
      "Train Preds: tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 434 Train Accuracy: 0.9046\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 434 Test Accuracy: 0.6128\n",
      "Epoch 434/500, Train Loss: 0.0842, Test Loss: 2.4500\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 435 Train Accuracy: 0.9030\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 435 Test Accuracy: 0.5791\n",
      "Epoch 435/500, Train Loss: 0.0799, Test Loss: 2.6928\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 436 Train Accuracy: 0.8937\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 436 Test Accuracy: 0.5892\n",
      "Epoch 436/500, Train Loss: 0.0945, Test Loss: 2.3391\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 437 Train Accuracy: 0.9148\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 437 Test Accuracy: 0.6128\n",
      "Epoch 437/500, Train Loss: 0.0738, Test Loss: 2.3420\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 438 Train Accuracy: 0.9046\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 438 Test Accuracy: 0.5387\n",
      "Epoch 438/500, Train Loss: 0.0793, Test Loss: 2.5481\n",
      "Train Preds: tensor([1., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 439 Train Accuracy: 0.9013\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 439 Test Accuracy: 0.5892\n",
      "Epoch 439/500, Train Loss: 0.0747, Test Loss: 2.5808\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 440 Train Accuracy: 0.9300\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 440 Test Accuracy: 0.5758\n",
      "Epoch 440/500, Train Loss: 0.0777, Test Loss: 2.7574\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 0., 1., 1., 0.])\n",
      "Epoch 441 Train Accuracy: 0.9114\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 441 Test Accuracy: 0.5791\n",
      "Epoch 441/500, Train Loss: 0.0775, Test Loss: 2.6066\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 442 Train Accuracy: 0.9089\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 442 Test Accuracy: 0.5825\n",
      "Epoch 442/500, Train Loss: 0.0789, Test Loss: 2.6377\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 443 Train Accuracy: 0.9173\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 443 Test Accuracy: 0.5758\n",
      "Epoch 443/500, Train Loss: 0.0815, Test Loss: 2.7217\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 444 Train Accuracy: 0.8852\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 444 Test Accuracy: 0.5589\n",
      "Epoch 444/500, Train Loss: 0.1314, Test Loss: 1.9778\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 1.])\n",
      "Epoch 445 Train Accuracy: 0.8810\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 445 Test Accuracy: 0.5724\n",
      "Epoch 445/500, Train Loss: 0.0934, Test Loss: 2.9367\n",
      "Train Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 446 Train Accuracy: 0.9139\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 446 Test Accuracy: 0.5960\n",
      "Epoch 446/500, Train Loss: 0.0711, Test Loss: 2.6414\n",
      "Train Preds: tensor([0., 1., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 447 Train Accuracy: 0.8878\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 447 Test Accuracy: 0.5724\n",
      "Epoch 447/500, Train Loss: 0.0941, Test Loss: 2.9283\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 448 Train Accuracy: 0.9266\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 448 Test Accuracy: 0.5825\n",
      "Epoch 448/500, Train Loss: 0.0757, Test Loss: 2.8518\n",
      "Train Preds: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 449 Train Accuracy: 0.9055\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 449 Test Accuracy: 0.5589\n",
      "Epoch 449/500, Train Loss: 0.0745, Test Loss: 3.1562\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 450 Train Accuracy: 0.9063\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 450 Test Accuracy: 0.5522\n",
      "Epoch 450/500, Train Loss: 0.1017, Test Loss: 3.3371\n",
      "Train Preds: tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 451 Train Accuracy: 0.9139\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 451 Test Accuracy: 0.5589\n",
      "Epoch 451/500, Train Loss: 0.0720, Test Loss: 3.1921\n",
      "Train Preds: tensor([1., 1., 0., 0., 0., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 452 Train Accuracy: 0.9173\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 452 Test Accuracy: 0.5589\n",
      "Epoch 452/500, Train Loss: 0.0685, Test Loss: 3.1642\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 453 Train Accuracy: 0.9300\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 453 Test Accuracy: 0.5690\n",
      "Epoch 453/500, Train Loss: 0.0899, Test Loss: 3.1038\n",
      "Train Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 454 Train Accuracy: 0.9190\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 454 Test Accuracy: 0.5960\n",
      "Epoch 454/500, Train Loss: 0.0779, Test Loss: 2.7378\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 455 Train Accuracy: 0.9105\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 455 Test Accuracy: 0.5286\n",
      "Epoch 455/500, Train Loss: 0.0735, Test Loss: 2.9831\n",
      "Train Preds: tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 456 Train Accuracy: 0.9097\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 456 Test Accuracy: 0.5320\n",
      "Epoch 456/500, Train Loss: 0.0853, Test Loss: 2.9745\n",
      "Train Preds: tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Epoch 457 Train Accuracy: 0.9122\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 457 Test Accuracy: 0.5455\n",
      "Epoch 457/500, Train Loss: 0.0791, Test Loss: 3.1283\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Epoch 458 Train Accuracy: 0.9181\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 458 Test Accuracy: 0.5253\n",
      "Epoch 458/500, Train Loss: 0.0769, Test Loss: 2.5233\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 459 Train Accuracy: 0.9072\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 459 Test Accuracy: 0.5758\n",
      "Epoch 459/500, Train Loss: 0.0880, Test Loss: 2.8879\n",
      "Train Preds: tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 460 Train Accuracy: 0.9089\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 460 Test Accuracy: 0.5556\n",
      "Epoch 460/500, Train Loss: 0.0750, Test Loss: 3.2644\n",
      "Train Preds: tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 461 Train Accuracy: 0.9063\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 461 Test Accuracy: 0.5522\n",
      "Epoch 461/500, Train Loss: 0.0760, Test Loss: 3.1516\n",
      "Train Preds: tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 462 Train Accuracy: 0.9072\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 462 Test Accuracy: 0.5354\n",
      "Epoch 462/500, Train Loss: 0.0774, Test Loss: 3.1788\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\n",
      "Epoch 463 Train Accuracy: 0.9207\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 463 Test Accuracy: 0.5118\n",
      "Epoch 463/500, Train Loss: 0.0906, Test Loss: 2.3964\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 464 Train Accuracy: 0.9198\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 464 Test Accuracy: 0.5253\n",
      "Epoch 464/500, Train Loss: 0.0748, Test Loss: 3.9909\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 1., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 465 Train Accuracy: 0.9030\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 465 Test Accuracy: 0.5623\n",
      "Epoch 465/500, Train Loss: 0.0813, Test Loss: 3.4020\n",
      "Train Preds: tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 466 Train Accuracy: 0.9038\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 466 Test Accuracy: 0.5589\n",
      "Epoch 466/500, Train Loss: 0.0801, Test Loss: 3.4526\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 467 Train Accuracy: 0.9266\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 467 Test Accuracy: 0.5556\n",
      "Epoch 467/500, Train Loss: 0.0652, Test Loss: 3.1898\n",
      "Train Preds: tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 468 Train Accuracy: 0.9148\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 468 Test Accuracy: 0.5522\n",
      "Epoch 468/500, Train Loss: 0.0738, Test Loss: 3.2823\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 469 Train Accuracy: 0.9097\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 469 Test Accuracy: 0.5657\n",
      "Epoch 469/500, Train Loss: 0.0839, Test Loss: 3.1881\n",
      "Train Preds: tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 470 Train Accuracy: 0.9274\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 470 Test Accuracy: 0.5488\n",
      "Epoch 470/500, Train Loss: 0.0663, Test Loss: 3.0845\n",
      "Train Preds: tensor([1., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 471 Train Accuracy: 0.9232\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 471 Test Accuracy: 0.5623\n",
      "Epoch 471/500, Train Loss: 0.0713, Test Loss: 3.4484\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 472 Train Accuracy: 0.9114\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 472 Test Accuracy: 0.5455\n",
      "Epoch 472/500, Train Loss: 0.0823, Test Loss: 3.1937\n",
      "Train Preds: tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 473 Train Accuracy: 0.9165\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 473 Test Accuracy: 0.5657\n",
      "Epoch 473/500, Train Loss: 0.0838, Test Loss: 3.3618\n",
      "Train Preds: tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 474 Train Accuracy: 0.9249\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 474 Test Accuracy: 0.5892\n",
      "Epoch 474/500, Train Loss: 0.0676, Test Loss: 2.9848\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Epoch 475 Train Accuracy: 0.9198\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 475 Test Accuracy: 0.5556\n",
      "Epoch 475/500, Train Loss: 0.0700, Test Loss: 3.4476\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 476 Train Accuracy: 0.9080\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 476 Test Accuracy: 0.5017\n",
      "Epoch 476/500, Train Loss: 0.0795, Test Loss: 3.2364\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "Train Labels: tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 477 Train Accuracy: 0.9207\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 477 Test Accuracy: 0.5993\n",
      "Epoch 477/500, Train Loss: 0.0731, Test Loss: 2.7511\n",
      "Train Preds: tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 478 Train Accuracy: 0.9190\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 478 Test Accuracy: 0.5455\n",
      "Epoch 478/500, Train Loss: 0.0774, Test Loss: 2.8627\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 479 Train Accuracy: 0.9030\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 479 Test Accuracy: 0.5522\n",
      "Epoch 479/500, Train Loss: 0.0781, Test Loss: 3.2169\n",
      "Train Preds: tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 1., 0., 1., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 480 Train Accuracy: 0.9021\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 480 Test Accuracy: 0.5253\n",
      "Epoch 480/500, Train Loss: 0.0841, Test Loss: 3.1837\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 481 Train Accuracy: 0.9097\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 481 Test Accuracy: 0.5185\n",
      "Epoch 481/500, Train Loss: 0.0802, Test Loss: 3.0609\n",
      "Train Preds: tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Epoch 482 Train Accuracy: 0.9156\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 482 Test Accuracy: 0.5152\n",
      "Epoch 482/500, Train Loss: 0.0903, Test Loss: 3.2424\n",
      "Train Preds: tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 483 Train Accuracy: 0.9249\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 483 Test Accuracy: 0.5387\n",
      "Epoch 483/500, Train Loss: 0.0665, Test Loss: 3.8663\n",
      "Train Preds: tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 484 Train Accuracy: 0.9291\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 484 Test Accuracy: 0.5286\n",
      "Epoch 484/500, Train Loss: 0.0712, Test Loss: 4.0615\n",
      "Train Preds: tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 485 Train Accuracy: 0.9156\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 485 Test Accuracy: 0.5387\n",
      "Epoch 485/500, Train Loss: 0.0817, Test Loss: 4.2791\n",
      "Train Preds: tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Train Labels: tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 486 Train Accuracy: 0.9105\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 486 Test Accuracy: 0.5253\n",
      "Epoch 486/500, Train Loss: 0.1099, Test Loss: 2.6115\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 1.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Epoch 487 Train Accuracy: 0.9224\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 487 Test Accuracy: 0.5320\n",
      "Epoch 487/500, Train Loss: 0.0802, Test Loss: 4.0205\n",
      "Train Preds: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 488 Train Accuracy: 0.9063\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 488 Test Accuracy: 0.5421\n",
      "Epoch 488/500, Train Loss: 0.0810, Test Loss: 3.3817\n",
      "Train Preds: tensor([1., 0., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Train Labels: tensor([1., 0., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 489 Train Accuracy: 0.9198\n",
      "Test Preds: tensor([0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Test Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 489 Test Accuracy: 0.5354\n",
      "Epoch 489/500, Train Loss: 0.0730, Test Loss: 3.7817\n",
      "Train Preds: tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "Train Labels: tensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50439854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: \n",
    "# add more dense layers maybe it can help with non linearity of the map add 3 fully connected layers\n",
    "# learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cade84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3423fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f0aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d665b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bcc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a2300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0abb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
