{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "690b705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_lfp_model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cf93163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Config ------------\n",
    "SEGMENT_LENGTH = 125000  # 1 second @ 24kHz\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 200\n",
    "LOG_DIR = \"runs/siamese_lfp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ad389620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Data Preparation ------------\n",
    "def segment_data(data, segment_length):\n",
    "    num_segments = len(data) // segment_length\n",
    "    segments = np.array(np.split(data[:num_segments * segment_length], num_segments))\n",
    "    np.random.shuffle(segments)\n",
    "    return segments\n",
    "\n",
    "\n",
    "# def create_pairs(gpi_segments, stn_segments):\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "\n",
    "#     # GPi-GPi (label 0)\n",
    "#     for i in range(len(gpi_segments) - 1):\n",
    "#         pairs.append((gpi_segments[i], gpi_segments[i+1]))\n",
    "#         labels.append(0)\n",
    "\n",
    "#     # STN-STN (label 0)\n",
    "#     for i in range(len(stn_segments) - 1):\n",
    "#         pairs.append((stn_segments[i], stn_segments[i+1]))\n",
    "#         labels.append(0)\n",
    "\n",
    "#     # GPi-STN (label 1)\n",
    "#     for i in range(min(len(gpi_segments), len(stn_segments))):\n",
    "#         pairs.append((gpi_segments[i], stn_segments[i]))\n",
    "#         labels.append(1)\n",
    "\n",
    "#     ratio_similar = labels.count(0) / len(labels)\n",
    "#     print(f\"Similarity label ratio: {ratio_similar:.2f} similar (label 0), {1 - ratio_similar:.2f} dissimilar (label 1)\")\n",
    "\n",
    "#     return pairs, labels\n",
    "\n",
    "def create_pairs(gpi_segments, stn_segments):\n",
    "    # GPi-GPi (label 0)\n",
    "    gpi_gpi_pairs = [(gpi_segments[i], gpi_segments[i+1]) for i in range(len(gpi_segments) - 1)]\n",
    "    gpi_gpi_labels = [0] * len(gpi_gpi_pairs)\n",
    "\n",
    "    # STN-STN (label 0)\n",
    "    stn_stn_pairs = [(stn_segments[i], stn_segments[i+1]) for i in range(len(stn_segments) - 1)]\n",
    "    stn_stn_labels = [0] * len(stn_stn_pairs)\n",
    "\n",
    "    # GPi-STN (label 1)\n",
    "    gpi_stn_pairs = [(gpi_segments[i], stn_segments[i]) for i in range(min(len(gpi_segments), len(stn_segments)))]\n",
    "    gpi_stn_labels = [1] * len(gpi_stn_pairs)\n",
    "\n",
    "    # Combine similar pairs\n",
    "    similar_pairs = gpi_gpi_pairs + stn_stn_pairs\n",
    "    similar_labels = gpi_gpi_labels + stn_stn_labels\n",
    "\n",
    "    # Balance both classes\n",
    "    min_len = min(len(similar_pairs), len(gpi_stn_pairs))\n",
    "    balanced_pairs = similar_pairs[:min_len] + gpi_stn_pairs[:min_len]\n",
    "    balanced_labels = similar_labels[:min_len] + gpi_stn_labels[:min_len]\n",
    "\n",
    "    ratio_similar = balanced_labels.count(0) / len(balanced_labels)\n",
    "    print(f\"Balanced similarity label ratio: {ratio_similar:.2f} similar (label 0), {1 - ratio_similar:.2f} dissimilar (label 1)\")\n",
    "\n",
    "    return balanced_pairs, balanced_labels\n",
    "\n",
    "\n",
    "class LFPDataset(Dataset):\n",
    "    def __init__(self, pairs, labels):\n",
    "        self.pairs = pairs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, x2 = self.pairs[idx]\n",
    "        x1 = torch.tensor(x1, dtype=torch.float32).unsqueeze(0)\n",
    "        x2 = torch.tensor(x2, dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return x1, x2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "86b0c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Model Definition ------------\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        # self.layers = nn.ModuleList([\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv1d(1, 4, kernel_size=16, stride=2, padding=8),\n",
    "        #     nn.BatchNorm1d(4),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv1d(4, 8, kernel_size=32, stride=2, padding=16),\n",
    "        #     nn.BatchNorm1d(8),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv1d(8, 16, kernel_size=64, stride=2, padding=32),\n",
    "        #     nn.BatchNorm1d(16),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.1),\n",
    "        #     nn.Conv1d(16, 32, kernel_size=128, stride=2, padding=64),\n",
    "        #     nn.BatchNorm1d(32),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.1),\n",
    "        #     nn.Conv1d(32, 64, kernel_size=256, stride=2, padding=128),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     # nn.Dropout(0.1),\n",
    "        #     nn.Conv1d(64, 64, kernel_size=512, stride=2, padding=256),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.AdaptiveAvgPool1d(1)\n",
    "        # ])\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(1, 32, kernel_size=32, stride=8, padding=0),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(32, 64, kernel_size=32, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=16, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=8, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(64, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        ])\n",
    "        self.fc = nn.Linear(64, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total:,}\\n\")\n",
    "    print(\"Trainable parameters by layer:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"{name:50} {param.numel():,}\")\n",
    "\n",
    "\n",
    "def print_model_summary(model, train_loader, device):\n",
    "    print(\"===== Sample Forward Pass Shape Info =====\")\n",
    "    x_sample = next(iter(train_loader))[0].to(device)\n",
    "    model.encoder(x_sample)\n",
    "    print(\"\\nModel Summary:\\n\")\n",
    "    print(model)\n",
    "    count_parameters(model)\n",
    "\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.encoder = CNNEncoder(embedding_dim)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        embed1 = self.encoder(x1)\n",
    "        embed2 = self.encoder(x2)\n",
    "        distance = F.pairwise_distance(embed1, embed2)\n",
    "        return distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c0ee84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- Training Loop ------------\n",
    "def train(model, dataloader, optimizer, criterion, device, writer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x1, x2, label) in enumerate(dataloader):\n",
    "        x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x1, x2)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        preds = (output > 0.5).float()\n",
    "        correct += (preds == label).sum().item()\n",
    "        total += label.size(0)\n",
    "        if i == 0:\n",
    "            print(\"Preds:\", preds[:10])\n",
    "            print(\"Labels:\", label[:10])\n",
    "\n",
    "        writer.add_scalar('Train/Batch_Loss', loss.item(), epoch * len(dataloader) + i)\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1} Train Accuracy: {accuracy:.4f}\")\n",
    "    writer.add_scalar('Train/Epoch_Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', accuracy, epoch)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, writer, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, label in dataloader:\n",
    "            x1, x2, label = x1.to(device), x2.to(device), label.to(device)\n",
    "            output = model(x1, x2)\n",
    "            loss = criterion(output, label)\n",
    "            total_loss += loss.item()\n",
    "            preds = (output > 0.5).float()  # Same for both train and test\n",
    "            correct += (preds == label).sum().item()\n",
    "            total += label.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1} Test Accuracy: {accuracy:.4f}\")\n",
    "    writer.add_scalar('Test/Epoch_Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Test/Accuracy', accuracy, epoch)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "57497af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Run Pipeline ------------\n",
    "def main():\n",
    "    # Print dataset shape and sizes\n",
    "    print(\"===== Dataset Information =====\")\n",
    "    # TensorBoard setup\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "    writer = SummaryWriter(LOG_DIR)\n",
    "    # # Simulate random LFP-like signals\n",
    "    # GPiData = np.random.randn(24000 * 60 * 2)  # 2 minutes of data\n",
    "    # STNData = np.random.randn(24000 * 60 * 2)\n",
    "    # Simulate random LFP-like signals\n",
    "    # Generate synthetic LFP-like signals with sinusoids + noise\n",
    "\n",
    "    # fs = 24000\n",
    "    # duration_sec = 60 * 2\n",
    "    # t = np.linspace(0, duration_sec, fs * duration_sec, endpoint=False)\n",
    "\n",
    "    # gpi_signal = np.sin(2 * np.pi * 10 * t)  # 10 Hz sinusoid\n",
    "    # stn_signal = np.sin(2 * np.pi * 10 * t)  # 30 Hz sinusoid\n",
    "#ashaks\n",
    "    # GPiData = gpi_signal + 0.5 * np.random.randn(len(t))\n",
    "    # STNData = stn_signal + 0.5 * np.random.randn(len(t))\n",
    "\n",
    "    with h5py.File(\"F:\\Python Projects\\data\\period9\\microGPi1_L_4_CommonFiltered.mat\", \"r\") as f:\n",
    "        GPiData = np.array(f[\"data\"]).squeeze()\n",
    "        fs = int(np.array(f[\"fs\"]).squeeze())\n",
    "        # rtesting\n",
    "\n",
    "    # for Sina's PC: F:\\Python Projects\\data\\period9\n",
    "    # for shared PC: D:\\Sina\\Data\\period9\\microSTN_L_3_CommonFiltered.mat\n",
    "    with h5py.File(\"F:\\Python Projects\\data\\period9\\microSTN_L_3_CommonFiltered.mat\", \"r\") as f:\n",
    "        STNData = np.array(f[\"data\"]).squeeze()  # replace with your actual filename\n",
    "\n",
    "    # Segment\n",
    "    gpi_segments = segment_data(GPiData, SEGMENT_LENGTH)\n",
    "    stn_segments = segment_data(STNData, SEGMENT_LENGTH)\n",
    "    pairs, labels = create_pairs(gpi_segments, stn_segments)\n",
    "\n",
    "    # Split data\n",
    "    # train_pairs, test_pairs, train_labels, test_labels = train_test_split(pairs, labels, test_size=0.2, stratify=labels)\n",
    "    train_pairs, test_pairs, train_labels, test_labels = train_test_split( pairs, labels, test_size=0.2, stratify=labels, shuffle=True, random_state=42)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_ds = LFPDataset(train_pairs, train_labels)\n",
    "    test_ds = LFPDataset(test_pairs, test_labels)\n",
    "    print(f\"Train set: {len(train_ds)} pairs\")\n",
    "    print(f\"Test set: {len(test_ds)} pairs\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Model setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = SiameseNet(embedding_dim=EMBEDDING_DIM).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print_model_summary(model, train_loader, device)\n",
    "    print(\"===== Training Input Shape Info =====\")\n",
    "    for x1, x2, _ in train_loader:\n",
    "        print(f\"Train input shapes: x1: {x1.shape}, x2: {x2.shape}\")\n",
    "        break\n",
    "    print(\"===== Testing Input Shape Info =====\")\n",
    "\n",
    "    def contrastive_loss(distances, labels, margin=1.0):\n",
    "        labels = labels.float()\n",
    "        loss_similar = (1 - labels) * distances.pow(2)\n",
    "        loss_dissimilar = labels * F.relu(margin - distances).pow(2)\n",
    "        return torch.mean(loss_similar + loss_dissimilar)\n",
    "\n",
    "    criterion = contrastive_loss\n",
    "    for x1, x2, _ in test_loader:\n",
    "        print(f\"Test input shapes: x1: {x1.shape}, x2: {x2.shape}\")\n",
    "        break\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "    \n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device, writer, epoch)\n",
    "        test_loss = evaluate(model, test_loader, criterion, device, writer, epoch)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    writer.close()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Information =====\n",
      "Balanced similarity label ratio: 0.50 similar (label 0), 0.50 dissimilar (label 1)\n",
      "Train set: 1185 pairs\n",
      "Test set: 297 pairs\n",
      "Batch size: 64\n",
      "cpu\n",
      "===== Sample Forward Pass Shape Info =====\n",
      "\n",
      "Model Summary:\n",
      "\n",
      "SiameseNet(\n",
      "  (encoder): CNNEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Conv1d(1, 32, kernel_size=(32,), stride=(8,))\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Dropout(p=0.5, inplace=False)\n",
      "      (5): Conv1d(32, 64, kernel_size=(32,), stride=(2,))\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): ReLU()\n",
      "      (8): Dropout(p=0.5, inplace=False)\n",
      "      (9): Conv1d(64, 64, kernel_size=(16,), stride=(2,))\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU()\n",
      "      (12): Dropout(p=0.5, inplace=False)\n",
      "      (13): Conv1d(64, 64, kernel_size=(8,), stride=(2,))\n",
      "      (14): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Dropout(p=0.5, inplace=False)\n",
      "      (17): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (18): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU()\n",
      "      (20): Dropout(p=0.5, inplace=False)\n",
      "      (21): Conv1d(64, 64, kernel_size=(4,), stride=(2,))\n",
      "      (22): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (23): ReLU()\n",
      "      (24): Dropout(p=0.5, inplace=False)\n",
      "      (25): AdaptiveAvgPool1d(output_size=1)\n",
      "    )\n",
      "    (fc): Linear(in_features=64, out_features=128, bias=True)\n",
      "  )\n",
      ")\n",
      "Total trainable parameters: 207,008\n",
      "\n",
      "Trainable parameters by layer:\n",
      "encoder.layers.1.weight                            1,024\n",
      "encoder.layers.1.bias                              32\n",
      "encoder.layers.2.weight                            32\n",
      "encoder.layers.2.bias                              32\n",
      "encoder.layers.5.weight                            65,536\n",
      "encoder.layers.5.bias                              64\n",
      "encoder.layers.6.weight                            64\n",
      "encoder.layers.6.bias                              64\n",
      "encoder.layers.9.weight                            65,536\n",
      "encoder.layers.9.bias                              64\n",
      "encoder.layers.10.weight                           64\n",
      "encoder.layers.10.bias                             64\n",
      "encoder.layers.13.weight                           32,768\n",
      "encoder.layers.13.bias                             64\n",
      "encoder.layers.14.weight                           64\n",
      "encoder.layers.14.bias                             64\n",
      "encoder.layers.17.weight                           16,384\n",
      "encoder.layers.17.bias                             64\n",
      "encoder.layers.18.weight                           64\n",
      "encoder.layers.18.bias                             64\n",
      "encoder.layers.21.weight                           16,384\n",
      "encoder.layers.21.bias                             64\n",
      "encoder.layers.22.weight                           64\n",
      "encoder.layers.22.bias                             64\n",
      "encoder.fc.weight                                  8,192\n",
      "encoder.fc.bias                                    128\n",
      "===== Training Input Shape Info =====\n",
      "Train input shapes: x1: torch.Size([64, 1, 125000]), x2: torch.Size([64, 1, 125000])\n",
      "===== Testing Input Shape Info =====\n",
      "Test input shapes: x1: torch.Size([64, 1, 125000]), x2: torch.Size([64, 1, 125000])\n",
      "Preds: tensor([0., 1., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 1 Train Accuracy: 0.5291\n",
      "Epoch 1 Test Accuracy: 0.5017\n",
      "Epoch 1/200, Train Loss: 0.6657, Test Loss: 0.4987\n",
      "Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 2 Train Accuracy: 0.5359\n",
      "Epoch 2 Test Accuracy: 0.5017\n",
      "Epoch 2/200, Train Loss: 0.3038, Test Loss: 0.4351\n",
      "Preds: tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 1., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 3 Train Accuracy: 0.5232\n",
      "Epoch 3 Test Accuracy: 0.5017\n",
      "Epoch 3/200, Train Loss: 0.2671, Test Loss: 0.3620\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 4 Train Accuracy: 0.5122\n",
      "Epoch 4 Test Accuracy: 0.5051\n",
      "Epoch 4/200, Train Loss: 0.2672, Test Loss: 0.3530\n",
      "Preds: tensor([1., 0., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Epoch 5 Train Accuracy: 0.5165\n",
      "Epoch 5 Test Accuracy: 0.5253\n",
      "Epoch 5/200, Train Loss: 0.2623, Test Loss: 0.3346\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Epoch 6 Train Accuracy: 0.5224\n",
      "Epoch 6 Test Accuracy: 0.5219\n",
      "Epoch 6/200, Train Loss: 0.2618, Test Loss: 0.3673\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 7 Train Accuracy: 0.5190\n",
      "Epoch 7 Test Accuracy: 0.5152\n",
      "Epoch 7/200, Train Loss: 0.2640, Test Loss: 0.3599\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 8 Train Accuracy: 0.5165\n",
      "Epoch 8 Test Accuracy: 0.5185\n",
      "Epoch 8/200, Train Loss: 0.2616, Test Loss: 0.3707\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 9 Train Accuracy: 0.5097\n",
      "Epoch 9 Test Accuracy: 0.4983\n",
      "Epoch 9/200, Train Loss: 0.2626, Test Loss: 0.3405\n",
      "Preds: tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 10 Train Accuracy: 0.5190\n",
      "Epoch 10 Test Accuracy: 0.5219\n",
      "Epoch 10/200, Train Loss: 0.2624, Test Loss: 0.3411\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 1., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 11 Train Accuracy: 0.5215\n",
      "Epoch 11 Test Accuracy: 0.5219\n",
      "Epoch 11/200, Train Loss: 0.2621, Test Loss: 0.3117\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 12 Train Accuracy: 0.5105\n",
      "Epoch 12 Test Accuracy: 0.5084\n",
      "Epoch 12/200, Train Loss: 0.2608, Test Loss: 0.3391\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 13 Train Accuracy: 0.5114\n",
      "Epoch 13 Test Accuracy: 0.5118\n",
      "Epoch 13/200, Train Loss: 0.2589, Test Loss: 0.3800\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Epoch 14 Train Accuracy: 0.4979\n",
      "Epoch 14 Test Accuracy: 0.5152\n",
      "Epoch 14/200, Train Loss: 0.2590, Test Loss: 0.3822\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 15 Train Accuracy: 0.5173\n",
      "Epoch 15 Test Accuracy: 0.5084\n",
      "Epoch 15/200, Train Loss: 0.2592, Test Loss: 0.3443\n",
      "Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 16 Train Accuracy: 0.5105\n",
      "Epoch 16 Test Accuracy: 0.5084\n",
      "Epoch 16/200, Train Loss: 0.2613, Test Loss: 0.3488\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 17 Train Accuracy: 0.5122\n",
      "Epoch 17 Test Accuracy: 0.5017\n",
      "Epoch 17/200, Train Loss: 0.2598, Test Loss: 0.3672\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 18 Train Accuracy: 0.5181\n",
      "Epoch 18 Test Accuracy: 0.5084\n",
      "Epoch 18/200, Train Loss: 0.2574, Test Loss: 0.3533\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 19 Train Accuracy: 0.5114\n",
      "Epoch 19 Test Accuracy: 0.5488\n",
      "Epoch 19/200, Train Loss: 0.2592, Test Loss: 0.3636\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 1.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 20 Train Accuracy: 0.5190\n",
      "Epoch 20 Test Accuracy: 0.5387\n",
      "Epoch 20/200, Train Loss: 0.2566, Test Loss: 0.3563\n",
      "Preds: tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 21 Train Accuracy: 0.5165\n",
      "Epoch 21 Test Accuracy: 0.5185\n",
      "Epoch 21/200, Train Loss: 0.2596, Test Loss: 0.3488\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 22 Train Accuracy: 0.5139\n",
      "Epoch 22 Test Accuracy: 0.5118\n",
      "Epoch 22/200, Train Loss: 0.2558, Test Loss: 0.3468\n",
      "Preds: tensor([1., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 23 Train Accuracy: 0.5122\n",
      "Epoch 23 Test Accuracy: 0.5084\n",
      "Epoch 23/200, Train Loss: 0.2573, Test Loss: 0.3484\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 1., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 24 Train Accuracy: 0.5055\n",
      "Epoch 24 Test Accuracy: 0.5084\n",
      "Epoch 24/200, Train Loss: 0.2567, Test Loss: 0.3566\n",
      "Preds: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 0., 1., 1., 1., 1.])\n",
      "Epoch 25 Train Accuracy: 0.5241\n",
      "Epoch 25 Test Accuracy: 0.5253\n",
      "Epoch 25/200, Train Loss: 0.2570, Test Loss: 0.3240\n",
      "Preds: tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 26 Train Accuracy: 0.5173\n",
      "Epoch 26 Test Accuracy: 0.5051\n",
      "Epoch 26/200, Train Loss: 0.2579, Test Loss: 0.3441\n",
      "Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 27 Train Accuracy: 0.5257\n",
      "Epoch 27 Test Accuracy: 0.5219\n",
      "Epoch 27/200, Train Loss: 0.2549, Test Loss: 0.3393\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 1.])\n",
      "Labels: tensor([0., 0., 1., 0., 1., 1., 0., 1., 1., 0.])\n",
      "Epoch 28 Train Accuracy: 0.5283\n",
      "Epoch 28 Test Accuracy: 0.5185\n",
      "Epoch 28/200, Train Loss: 0.2537, Test Loss: 0.3294\n",
      "Preds: tensor([1., 0., 1., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Labels: tensor([1., 1., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 29 Train Accuracy: 0.5215\n",
      "Epoch 29 Test Accuracy: 0.5219\n",
      "Epoch 29/200, Train Loss: 0.2563, Test Loss: 0.3433\n",
      "Preds: tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 1., 0., 0., 0., 1., 1., 1., 0.])\n",
      "Epoch 30 Train Accuracy: 0.5148\n",
      "Epoch 30 Test Accuracy: 0.4983\n",
      "Epoch 30/200, Train Loss: 0.2545, Test Loss: 0.3437\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 31 Train Accuracy: 0.5215\n",
      "Epoch 31 Test Accuracy: 0.5118\n",
      "Epoch 31/200, Train Loss: 0.2563, Test Loss: 0.3557\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 32 Train Accuracy: 0.5038\n",
      "Epoch 32 Test Accuracy: 0.5152\n",
      "Epoch 32/200, Train Loss: 0.2576, Test Loss: 0.3841\n",
      "Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "Labels: tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 33 Train Accuracy: 0.5148\n",
      "Epoch 33 Test Accuracy: 0.5286\n",
      "Epoch 33/200, Train Loss: 0.2562, Test Loss: 0.3756\n",
      "Preds: tensor([0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Epoch 34 Train Accuracy: 0.5316\n",
      "Epoch 34 Test Accuracy: 0.5118\n",
      "Epoch 34/200, Train Loss: 0.2551, Test Loss: 0.3474\n",
      "Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 35 Train Accuracy: 0.5207\n",
      "Epoch 35 Test Accuracy: 0.5084\n",
      "Epoch 35/200, Train Loss: 0.2558, Test Loss: 0.3144\n",
      "Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 36 Train Accuracy: 0.5224\n",
      "Epoch 36 Test Accuracy: 0.5051\n",
      "Epoch 36/200, Train Loss: 0.2549, Test Loss: 0.3290\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 0., 1., 0., 0., 1., 0., 0., 1., 1.])\n",
      "Epoch 37 Train Accuracy: 0.5215\n",
      "Epoch 37 Test Accuracy: 0.5219\n",
      "Epoch 37/200, Train Loss: 0.2557, Test Loss: 0.3581\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 38 Train Accuracy: 0.5325\n",
      "Epoch 38 Test Accuracy: 0.5118\n",
      "Epoch 38/200, Train Loss: 0.2539, Test Loss: 0.3563\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Epoch 39 Train Accuracy: 0.5004\n",
      "Epoch 39 Test Accuracy: 0.5118\n",
      "Epoch 39/200, Train Loss: 0.2576, Test Loss: 0.3479\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 40 Train Accuracy: 0.5198\n",
      "Epoch 40 Test Accuracy: 0.5286\n",
      "Epoch 40/200, Train Loss: 0.2560, Test Loss: 0.3121\n",
      "Preds: tensor([1., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 41 Train Accuracy: 0.5224\n",
      "Epoch 41 Test Accuracy: 0.5051\n",
      "Epoch 41/200, Train Loss: 0.2549, Test Loss: 0.3380\n",
      "Preds: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 0., 1., 1., 0.])\n",
      "Epoch 42 Train Accuracy: 0.5173\n",
      "Epoch 42 Test Accuracy: 0.5219\n",
      "Epoch 42/200, Train Loss: 0.2548, Test Loss: 0.3391\n",
      "Preds: tensor([1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 0., 1., 1., 0., 1., 0., 0.])\n",
      "Epoch 43 Train Accuracy: 0.5325\n",
      "Epoch 43 Test Accuracy: 0.5286\n",
      "Epoch 43/200, Train Loss: 0.2507, Test Loss: 0.3336\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 44 Train Accuracy: 0.5148\n",
      "Epoch 44 Test Accuracy: 0.5219\n",
      "Epoch 44/200, Train Loss: 0.2538, Test Loss: 0.3300\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([1., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 45 Train Accuracy: 0.5207\n",
      "Epoch 45 Test Accuracy: 0.5286\n",
      "Epoch 45/200, Train Loss: 0.2540, Test Loss: 0.3531\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 46 Train Accuracy: 0.5266\n",
      "Epoch 46 Test Accuracy: 0.5320\n",
      "Epoch 46/200, Train Loss: 0.2536, Test Loss: 0.3210\n",
      "Preds: tensor([0., 0., 1., 0., 1., 1., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch 47 Train Accuracy: 0.5325\n",
      "Epoch 47 Test Accuracy: 0.5253\n",
      "Epoch 47/200, Train Loss: 0.2526, Test Loss: 0.3301\n",
      "Preds: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 48 Train Accuracy: 0.5131\n",
      "Epoch 48 Test Accuracy: 0.5152\n",
      "Epoch 48/200, Train Loss: 0.2557, Test Loss: 0.3094\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 49 Train Accuracy: 0.5156\n",
      "Epoch 49 Test Accuracy: 0.5354\n",
      "Epoch 49/200, Train Loss: 0.2555, Test Loss: 0.3244\n",
      "Preds: tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 50 Train Accuracy: 0.5063\n",
      "Epoch 50 Test Accuracy: 0.5320\n",
      "Epoch 50/200, Train Loss: 0.2549, Test Loss: 0.3684\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 51 Train Accuracy: 0.5089\n",
      "Epoch 51 Test Accuracy: 0.5556\n",
      "Epoch 51/200, Train Loss: 0.2536, Test Loss: 0.3992\n",
      "Preds: tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 52 Train Accuracy: 0.5156\n",
      "Epoch 52 Test Accuracy: 0.5354\n",
      "Epoch 52/200, Train Loss: 0.2548, Test Loss: 0.3580\n",
      "Preds: tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 1.])\n",
      "Labels: tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 53 Train Accuracy: 0.5080\n",
      "Epoch 53 Test Accuracy: 0.5455\n",
      "Epoch 53/200, Train Loss: 0.2530, Test Loss: 0.3077\n",
      "Preds: tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 54 Train Accuracy: 0.5097\n",
      "Epoch 54 Test Accuracy: 0.5522\n",
      "Epoch 54/200, Train Loss: 0.2541, Test Loss: 0.3103\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Epoch 55 Train Accuracy: 0.5122\n",
      "Epoch 55 Test Accuracy: 0.5421\n",
      "Epoch 55/200, Train Loss: 0.2520, Test Loss: 0.3009\n",
      "Preds: tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 56 Train Accuracy: 0.5224\n",
      "Epoch 56 Test Accuracy: 0.5152\n",
      "Epoch 56/200, Train Loss: 0.2526, Test Loss: 0.3200\n",
      "Preds: tensor([1., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 57 Train Accuracy: 0.5122\n",
      "Epoch 57 Test Accuracy: 0.5286\n",
      "Epoch 57/200, Train Loss: 0.2521, Test Loss: 0.3277\n",
      "Preds: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 58 Train Accuracy: 0.5181\n",
      "Epoch 58 Test Accuracy: 0.5387\n",
      "Epoch 58/200, Train Loss: 0.2559, Test Loss: 0.3797\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 59 Train Accuracy: 0.5165\n",
      "Epoch 59 Test Accuracy: 0.5320\n",
      "Epoch 59/200, Train Loss: 0.2544, Test Loss: 0.3533\n",
      "Preds: tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 1.])\n",
      "Epoch 60 Train Accuracy: 0.5165\n",
      "Epoch 60 Test Accuracy: 0.5690\n",
      "Epoch 60/200, Train Loss: 0.2526, Test Loss: 0.3210\n",
      "Preds: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 61 Train Accuracy: 0.5308\n",
      "Epoch 61 Test Accuracy: 0.5387\n",
      "Epoch 61/200, Train Loss: 0.2486, Test Loss: 0.3605\n",
      "Preds: tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Epoch 62 Train Accuracy: 0.5224\n",
      "Epoch 62 Test Accuracy: 0.5421\n",
      "Epoch 62/200, Train Loss: 0.2528, Test Loss: 0.3386\n",
      "Preds: tensor([1., 1., 0., 1., 0., 0., 1., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Epoch 63 Train Accuracy: 0.5316\n",
      "Epoch 63 Test Accuracy: 0.5286\n",
      "Epoch 63/200, Train Loss: 0.2520, Test Loss: 0.3182\n",
      "Preds: tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 1., 0., 1., 0., 0., 1.])\n",
      "Epoch 64 Train Accuracy: 0.5215\n",
      "Epoch 64 Test Accuracy: 0.5185\n",
      "Epoch 64/200, Train Loss: 0.2528, Test Loss: 0.3677\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 65 Train Accuracy: 0.5249\n",
      "Epoch 65 Test Accuracy: 0.5286\n",
      "Epoch 65/200, Train Loss: 0.2516, Test Loss: 0.3147\n",
      "Preds: tensor([1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 0.])\n",
      "Epoch 66 Train Accuracy: 0.5173\n",
      "Epoch 66 Test Accuracy: 0.5488\n",
      "Epoch 66/200, Train Loss: 0.2521, Test Loss: 0.3085\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 67 Train Accuracy: 0.5089\n",
      "Epoch 67 Test Accuracy: 0.5118\n",
      "Epoch 67/200, Train Loss: 0.2513, Test Loss: 0.3734\n",
      "Preds: tensor([0., 0., 0., 1., 1., 0., 1., 0., 0., 1.])\n",
      "Labels: tensor([1., 0., 0., 1., 1., 1., 1., 1., 0., 1.])\n",
      "Epoch 68 Train Accuracy: 0.5173\n",
      "Epoch 68 Test Accuracy: 0.5354\n",
      "Epoch 68/200, Train Loss: 0.2541, Test Loss: 0.3276\n",
      "Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 1., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 69 Train Accuracy: 0.5359\n",
      "Epoch 69 Test Accuracy: 0.5118\n",
      "Epoch 69/200, Train Loss: 0.2516, Test Loss: 0.3473\n",
      "Preds: tensor([0., 1., 0., 0., 0., 1., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 1., 0., 0., 1., 1.])\n",
      "Epoch 70 Train Accuracy: 0.5055\n",
      "Epoch 70 Test Accuracy: 0.5421\n",
      "Epoch 70/200, Train Loss: 0.2542, Test Loss: 0.3210\n",
      "Preds: tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 0.])\n",
      "Epoch 71 Train Accuracy: 0.5139\n",
      "Epoch 71 Test Accuracy: 0.5051\n",
      "Epoch 71/200, Train Loss: 0.2506, Test Loss: 0.3775\n",
      "Preds: tensor([1., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Labels: tensor([1., 1., 1., 1., 0., 1., 1., 1., 1., 1.])\n",
      "Epoch 72 Train Accuracy: 0.5249\n",
      "Epoch 72 Test Accuracy: 0.5152\n",
      "Epoch 72/200, Train Loss: 0.2528, Test Loss: 0.3543\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1.])\n",
      "Epoch 73 Train Accuracy: 0.5105\n",
      "Epoch 73 Test Accuracy: 0.5589\n",
      "Epoch 73/200, Train Loss: 0.2520, Test Loss: 0.3502\n",
      "Preds: tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Epoch 74 Train Accuracy: 0.5224\n",
      "Epoch 74 Test Accuracy: 0.5724\n",
      "Epoch 74/200, Train Loss: 0.2514, Test Loss: 0.3549\n",
      "Preds: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 0., 0., 1., 1., 1., 0., 0.])\n",
      "Epoch 75 Train Accuracy: 0.5131\n",
      "Epoch 75 Test Accuracy: 0.5320\n",
      "Epoch 75/200, Train Loss: 0.2534, Test Loss: 0.3163\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 76 Train Accuracy: 0.5291\n",
      "Epoch 76 Test Accuracy: 0.5017\n",
      "Epoch 76/200, Train Loss: 0.2503, Test Loss: 0.3656\n",
      "Preds: tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 77 Train Accuracy: 0.5460\n",
      "Epoch 77 Test Accuracy: 0.5455\n",
      "Epoch 77/200, Train Loss: 0.2511, Test Loss: 0.3315\n",
      "Preds: tensor([0., 1., 1., 0., 0., 0., 1., 0., 0., 1.])\n",
      "Labels: tensor([0., 1., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Epoch 78 Train Accuracy: 0.5308\n",
      "Epoch 78 Test Accuracy: 0.5690\n",
      "Epoch 78/200, Train Loss: 0.2493, Test Loss: 0.3401\n",
      "Preds: tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 1., 1.])\n",
      "Epoch 79 Train Accuracy: 0.5418\n",
      "Epoch 79 Test Accuracy: 0.5387\n",
      "Epoch 79/200, Train Loss: 0.2501, Test Loss: 0.4012\n",
      "Preds: tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Labels: tensor([0., 1., 1., 0., 1., 1., 0., 1., 1., 1.])\n",
      "Epoch 80 Train Accuracy: 0.5257\n",
      "Epoch 80 Test Accuracy: 0.5387\n",
      "Epoch 80/200, Train Loss: 0.2527, Test Loss: 0.3716\n",
      "Preds: tensor([1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])\n",
      "Labels: tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 81 Train Accuracy: 0.5316\n",
      "Epoch 81 Test Accuracy: 0.5051\n",
      "Epoch 81/200, Train Loss: 0.2497, Test Loss: 0.4112\n",
      "Preds: tensor([0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Labels: tensor([0., 0., 1., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Epoch 82 Train Accuracy: 0.5156\n",
      "Epoch 82 Test Accuracy: 0.5118\n",
      "Epoch 82/200, Train Loss: 0.2514, Test Loss: 0.3532\n",
      "Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 83 Train Accuracy: 0.5241\n",
      "Epoch 83 Test Accuracy: 0.5758\n",
      "Epoch 83/200, Train Loss: 0.2506, Test Loss: 0.3792\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "Epoch 84 Train Accuracy: 0.5300\n",
      "Epoch 84 Test Accuracy: 0.5556\n",
      "Epoch 84/200, Train Loss: 0.2492, Test Loss: 0.3499\n",
      "Preds: tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 1., 1., 0., 1., 1., 0., 0.])\n",
      "Epoch 85 Train Accuracy: 0.5266\n",
      "Epoch 85 Test Accuracy: 0.5455\n",
      "Epoch 85/200, Train Loss: 0.2516, Test Loss: 0.4018\n",
      "Preds: tensor([1., 0., 0., 1., 0., 1., 1., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 86 Train Accuracy: 0.5181\n",
      "Epoch 86 Test Accuracy: 0.5690\n",
      "Epoch 86/200, Train Loss: 0.2518, Test Loss: 0.3350\n",
      "Preds: tensor([1., 0., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0.])\n",
      "Epoch 87 Train Accuracy: 0.5114\n",
      "Epoch 87 Test Accuracy: 0.5623\n",
      "Epoch 87/200, Train Loss: 0.2516, Test Loss: 0.3587\n",
      "Preds: tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 88 Train Accuracy: 0.5367\n",
      "Epoch 88 Test Accuracy: 0.5657\n",
      "Epoch 88/200, Train Loss: 0.2498, Test Loss: 0.3479\n",
      "Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "Epoch 89 Train Accuracy: 0.5181\n",
      "Epoch 89 Test Accuracy: 0.5219\n",
      "Epoch 89/200, Train Loss: 0.2516, Test Loss: 0.3358\n",
      "Preds: tensor([1., 1., 0., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 0., 1., 0., 1., 1., 0., 1.])\n",
      "Epoch 90 Train Accuracy: 0.5139\n",
      "Epoch 90 Test Accuracy: 0.5354\n",
      "Epoch 90/200, Train Loss: 0.2541, Test Loss: 0.4097\n",
      "Preds: tensor([1., 1., 1., 1., 1., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 1.])\n",
      "Epoch 91 Train Accuracy: 0.5350\n",
      "Epoch 91 Test Accuracy: 0.5488\n",
      "Epoch 91/200, Train Loss: 0.2485, Test Loss: 0.3374\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 0., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 92 Train Accuracy: 0.5342\n",
      "Epoch 92 Test Accuracy: 0.5219\n",
      "Epoch 92/200, Train Loss: 0.2484, Test Loss: 0.3459\n",
      "Preds: tensor([1., 1., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 1., 0., 0., 1., 0., 1., 1.])\n",
      "Epoch 93 Train Accuracy: 0.5342\n",
      "Epoch 93 Test Accuracy: 0.5522\n",
      "Epoch 93/200, Train Loss: 0.2494, Test Loss: 0.3503\n",
      "Preds: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 94 Train Accuracy: 0.5291\n",
      "Epoch 94 Test Accuracy: 0.5892\n",
      "Epoch 94/200, Train Loss: 0.2497, Test Loss: 0.3732\n",
      "Preds: tensor([0., 0., 0., 1., 1., 1., 1., 1., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 1., 1., 1., 0.])\n",
      "Epoch 95 Train Accuracy: 0.5190\n",
      "Epoch 95 Test Accuracy: 0.5556\n",
      "Epoch 95/200, Train Loss: 0.2501, Test Loss: 0.3539\n",
      "Preds: tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([0., 0., 1., 1., 1., 0., 1., 0., 0., 0.])\n",
      "Epoch 96 Train Accuracy: 0.5097\n",
      "Epoch 96 Test Accuracy: 0.5892\n",
      "Epoch 96/200, Train Loss: 0.2521, Test Loss: 0.3522\n",
      "Preds: tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 1.])\n",
      "Epoch 97 Train Accuracy: 0.5443\n",
      "Epoch 97 Test Accuracy: 0.5320\n",
      "Epoch 97/200, Train Loss: 0.2493, Test Loss: 0.4384\n",
      "Preds: tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 98 Train Accuracy: 0.5266\n",
      "Epoch 98 Test Accuracy: 0.5657\n",
      "Epoch 98/200, Train Loss: 0.2483, Test Loss: 0.3611\n",
      "Preds: tensor([1., 1., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 0.])\n",
      "Epoch 99 Train Accuracy: 0.5207\n",
      "Epoch 99 Test Accuracy: 0.5286\n",
      "Epoch 99/200, Train Loss: 0.2511, Test Loss: 0.3953\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 1., 0., 0., 1., 1., 0., 1., 1.])\n",
      "Epoch 100 Train Accuracy: 0.5004\n",
      "Epoch 100 Test Accuracy: 0.5354\n",
      "Epoch 100/200, Train Loss: 0.2516, Test Loss: 0.3735\n",
      "Preds: tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 1., 1., 1., 0., 1., 0.])\n",
      "Epoch 101 Train Accuracy: 0.5426\n",
      "Epoch 101 Test Accuracy: 0.5556\n",
      "Epoch 101/200, Train Loss: 0.2495, Test Loss: 0.4241\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 0.])\n",
      "Epoch 102 Train Accuracy: 0.5325\n",
      "Epoch 102 Test Accuracy: 0.5253\n",
      "Epoch 102/200, Train Loss: 0.2506, Test Loss: 0.4115\n",
      "Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([1., 0., 1., 1., 0., 1., 0., 0., 1., 0.])\n",
      "Epoch 103 Train Accuracy: 0.5350\n",
      "Epoch 103 Test Accuracy: 0.5488\n",
      "Epoch 103/200, Train Loss: 0.2523, Test Loss: 0.3891\n",
      "Preds: tensor([0., 0., 0., 0., 1., 1., 1., 0., 0., 1.])\n",
      "Labels: tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0.])\n",
      "Epoch 104 Train Accuracy: 0.5097\n",
      "Epoch 104 Test Accuracy: 0.5354\n",
      "Epoch 104/200, Train Loss: 0.2535, Test Loss: 0.5079\n",
      "Preds: tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 1.])\n",
      "Labels: tensor([1., 1., 0., 1., 1., 1., 1., 0., 0., 1.])\n",
      "Epoch 105 Train Accuracy: 0.5291\n",
      "Epoch 105 Test Accuracy: 0.5051\n",
      "Epoch 105/200, Train Loss: 0.2509, Test Loss: 0.4330\n",
      "Preds: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 1.])\n",
      "Epoch 106 Train Accuracy: 0.5468\n",
      "Epoch 106 Test Accuracy: 0.5690\n",
      "Epoch 106/200, Train Loss: 0.2495, Test Loss: 0.3405\n",
      "Preds: tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 1., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "Epoch 107 Train Accuracy: 0.5443\n",
      "Epoch 107 Test Accuracy: 0.5488\n",
      "Epoch 107/200, Train Loss: 0.2478, Test Loss: 0.3382\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n",
      "Labels: tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
      "Epoch 108 Train Accuracy: 0.5325\n",
      "Epoch 108 Test Accuracy: 0.5657\n",
      "Epoch 108/200, Train Loss: 0.2485, Test Loss: 0.4108\n",
      "Preds: tensor([0., 1., 0., 0., 1., 0., 1., 0., 1., 0.])\n",
      "Labels: tensor([1., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "Epoch 109 Train Accuracy: 0.5291\n",
      "Epoch 109 Test Accuracy: 0.5219\n",
      "Epoch 109/200, Train Loss: 0.2484, Test Loss: 0.4216\n",
      "Preds: tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "Labels: tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])\n",
      "Epoch 110 Train Accuracy: 0.5376\n",
      "Epoch 110 Test Accuracy: 0.5421\n",
      "Epoch 110/200, Train Loss: 0.2484, Test Loss: 0.3854\n",
      "Preds: tensor([0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 0.])\n",
      "Epoch 111 Train Accuracy: 0.5384\n",
      "Epoch 111 Test Accuracy: 0.5118\n",
      "Epoch 111/200, Train Loss: 0.2475, Test Loss: 0.4266\n",
      "Preds: tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1.])\n",
      "Labels: tensor([1., 1., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "Epoch 112 Train Accuracy: 0.5426\n",
      "Epoch 112 Test Accuracy: 0.5724\n",
      "Epoch 112/200, Train Loss: 0.2478, Test Loss: 0.3824\n",
      "Preds: tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\n",
      "Epoch 113 Train Accuracy: 0.5477\n",
      "Epoch 113 Test Accuracy: 0.5556\n",
      "Epoch 113/200, Train Loss: 0.2489, Test Loss: 0.4358\n",
      "Preds: tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Labels: tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 1.])\n",
      "Epoch 114 Train Accuracy: 0.5257\n",
      "Epoch 114 Test Accuracy: 0.5522\n",
      "Epoch 114/200, Train Loss: 0.2490, Test Loss: 0.3883\n",
      "Preds: tensor([1., 0., 1., 0., 1., 0., 0., 1., 0., 1.])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 1., 1., 0., 1., 0.])\n",
      "Epoch 115 Train Accuracy: 0.5308\n",
      "Epoch 115 Test Accuracy: 0.5522\n",
      "Epoch 115/200, Train Loss: 0.2486, Test Loss: 0.3488\n",
      "Preds: tensor([0., 0., 1., 0., 1., 0., 0., 0., 1., 0.])\n",
      "Labels: tensor([0., 1., 0., 0., 1., 1., 0., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50439854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd612b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8e416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae17a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab46f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d560822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a670a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
